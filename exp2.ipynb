{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Total Transactions', 'Merchant', 'Aggregator', 'Bank',\n",
       "       'Transaction Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r'C:\\Users\\vishn\\OneDrive\\Documents\\meachine-learning\\datajuspay.xlsx')\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Total Transactions    Merchant Aggregator    Bank  \\\n",
      "0    4/14/2016                  21  Merchant 1       Agg2  Bank 2   \n",
      "1    4/14/2016                   9  Merchant 2       Agg2  Bank 2   \n",
      "2    4/14/2016                   3  Merchant 2       Agg2  Bank 1   \n",
      "3    4/14/2016                   7  Merchant 2       None  Bank 1   \n",
      "4    4/14/2016                 680  Merchant 1       Agg2  Bank 1   \n",
      "..         ...                 ...         ...        ...     ...   \n",
      "746  4/28/2016                1912  Merchant 1       Agg4  Bank 2   \n",
      "747  4/28/2016                2343  Merchant 1       Agg2  Bank 1   \n",
      "748  4/28/2016                  85  Merchant 1       Agg2  Bank 2   \n",
      "749  4/28/2016                 481  Merchant 1       Agg4  Bank 3   \n",
      "750  4/28/2016                  22  Merchant 1       Agg2  Bank 3   \n",
      "\n",
      "    Transaction Status  \n",
      "0                 None  \n",
      "1                 None  \n",
      "2              SUCCESS  \n",
      "3              SUCCESS  \n",
      "4                 None  \n",
      "..                 ...  \n",
      "746            SUCCESS  \n",
      "747            SUCCESS  \n",
      "748            SUCCESS  \n",
      "749            SUCCESS  \n",
      "750            SUCCESS  \n",
      "\n",
      "[751 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('datajuspay.db')\n",
    "\n",
    "df.to_sql('df', conn, index=False, if_exists='replace')\n",
    "\n",
    "query = \"SELECT * FROM df\"\n",
    "result_df = pd.read_sql(query, conn)\n",
    "\n",
    "conn.close()\n",
    "print(result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Total Transactions</th>\n",
       "      <th>Merchant</th>\n",
       "      <th>Aggregator</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Transaction Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/14/2016</td>\n",
       "      <td>21</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/14/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/14/2016</td>\n",
       "      <td>3</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/14/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/14/2016</td>\n",
       "      <td>680</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>4/28/2016</td>\n",
       "      <td>1912</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg4</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>4/28/2016</td>\n",
       "      <td>2343</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>4/28/2016</td>\n",
       "      <td>85</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>4/28/2016</td>\n",
       "      <td>481</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg4</td>\n",
       "      <td>Bank 3</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4/28/2016</td>\n",
       "      <td>22</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 3</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Total Transactions    Merchant Aggregator    Bank  \\\n",
       "0    4/14/2016                  21  Merchant 1       Agg2  Bank 2   \n",
       "1    4/14/2016                   9  Merchant 2       Agg2  Bank 2   \n",
       "2    4/14/2016                   3  Merchant 2       Agg2  Bank 1   \n",
       "3    4/14/2016                   7  Merchant 2        NaN  Bank 1   \n",
       "4    4/14/2016                 680  Merchant 1       Agg2  Bank 1   \n",
       "..         ...                 ...         ...        ...     ...   \n",
       "746  4/28/2016                1912  Merchant 1       Agg4  Bank 2   \n",
       "747  4/28/2016                2343  Merchant 1       Agg2  Bank 1   \n",
       "748  4/28/2016                  85  Merchant 1       Agg2  Bank 2   \n",
       "749  4/28/2016                 481  Merchant 1       Agg4  Bank 3   \n",
       "750  4/28/2016                  22  Merchant 1       Agg2  Bank 3   \n",
       "\n",
       "    Transaction Status  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2              SUCCESS  \n",
       "3              SUCCESS  \n",
       "4                  NaN  \n",
       "..                 ...  \n",
       "746            SUCCESS  \n",
       "747            SUCCESS  \n",
       "748            SUCCESS  \n",
       "749            SUCCESS  \n",
       "750            SUCCESS  \n",
       "\n",
       "[751 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of transactions without a transaction status: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Count the number of transactions without a transaction status\n",
    "transactions_without_status = df['Transaction Status'].isnull().sum()\n",
    "\n",
    "# Calculate the total number of transactions\n",
    "total_transactions = len(df)\n",
    "\n",
    "# Calculate the percentage of transactions without a transaction status\n",
    "percentage = (transactions_without_status / total_transactions) * 100\n",
    "\n",
    "print(\"Percentage of transactions without a transaction status:\", percentage, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of transactions without a Transaction Status: 34.62%\n"
     ]
    }
   ],
   "source": [
    "null_status_count = df['Transaction Status'].isnull().sum()\n",
    "\n",
    "# Total number of transactions\n",
    "total_transactions = len(df)\n",
    "\n",
    "# Calculating the percentage of transactions without a Transaction Status\n",
    "percentage_null_status = (null_status_count / total_transactions) * 100\n",
    "\n",
    "print(f\"Percentage of transactions without a Transaction Status: {percentage_null_status:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 15,000 transactions are processed without an aggregator: True\n"
     ]
    }
   ],
   "source": [
    "transactions_without_aggregator = df[df['Aggregator'].isnull()]\n",
    "\n",
    "# Total number of transactions without an aggregator\n",
    "total_transactions_without_aggregator = transactions_without_aggregator['Total Transactions'].sum()\n",
    "\n",
    "# Checking if the total number of transactions without an aggregator is more than 15,000\n",
    "result = total_transactions_without_aggregator > 15000\n",
    "\n",
    "print(\"More than 15,000 transactions are processed without an aggregator:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Aggregator  Success Count  Total Transactions  Success Rate\n",
      "0       Agg1             23                  53      0.433962\n",
      "4       Agg5             15                  37      0.405405\n",
      "2       Agg3             42                 123      0.341463\n",
      "3       Agg4             30                  88      0.340909\n",
      "1       Agg2             87                 258      0.337209\n"
     ]
    }
   ],
   "source": [
    "# success_transactions = df[df['Transaction Status'] == 'SUCCESS']\n",
    "\n",
    "# # Group the data by the 'Aggregator' column and count successful transactions\n",
    "# success_counts = success_transactions.groupby('Aggregator').size().reset_index(name='Success Count')\n",
    "\n",
    "# # Calculate total transactions for each aggregator\n",
    "# total_transactions = df.groupby('Aggregator').size().reset_index(name='Total Transactions')\n",
    "\n",
    "# # Merge success counts and total transactions\n",
    "# agg_success_rate = pd.merge(success_counts, total_transactions, on='Aggregator', how='left')\n",
    "\n",
    "# # Calculate success rate\n",
    "# agg_success_rate['Success Rate'] = agg_success_rate['Success Count'] / agg_success_rate['Total Transactions']\n",
    "\n",
    "# # Sort aggregators based on their success rates\n",
    "# sorted_agg_success_rate = agg_success_rate.sort_values(by='Success Rate', ascending=False)\n",
    "\n",
    "# print(sorted_agg_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Total Transactions</th>\n",
       "      <th>Merchant</th>\n",
       "      <th>Aggregator</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Transaction Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>21</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>9</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>3</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>7</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>680</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>1912</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg4</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2343</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>85</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>481</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg4</td>\n",
       "      <td>Bank 3</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>22</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 3</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Total Transactions    Merchant Aggregator    Bank  \\\n",
       "0   2016-04-14                  21  Merchant 1       Agg2  Bank 2   \n",
       "1   2016-04-14                   9  Merchant 2       Agg2  Bank 2   \n",
       "2   2016-04-14                   3  Merchant 2       Agg2  Bank 1   \n",
       "3   2016-04-14                   7  Merchant 2        NaN  Bank 1   \n",
       "4   2016-04-14                 680  Merchant 1       Agg2  Bank 1   \n",
       "..         ...                 ...         ...        ...     ...   \n",
       "746 2016-04-28                1912  Merchant 1       Agg4  Bank 2   \n",
       "747 2016-04-28                2343  Merchant 1       Agg2  Bank 1   \n",
       "748 2016-04-28                  85  Merchant 1       Agg2  Bank 2   \n",
       "749 2016-04-28                 481  Merchant 1       Agg4  Bank 3   \n",
       "750 2016-04-28                  22  Merchant 1       Agg2  Bank 3   \n",
       "\n",
       "    Transaction Status  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2              SUCCESS  \n",
       "3              SUCCESS  \n",
       "4                  NaN  \n",
       "..                 ...  \n",
       "746            SUCCESS  \n",
       "747            SUCCESS  \n",
       "748            SUCCESS  \n",
       "749            SUCCESS  \n",
       "750            SUCCESS  \n",
       "\n",
       "[751 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAIjCAYAAABh3KjvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABX4UlEQVR4nO3deVyU5f7/8feALAICoSwuuJu7qZiKqZiimGZppmmLS361UrMO5UlP5ZqZleaurVbn5NFcjpWViUvmgksuuZt5NEsFV8QVEK7fH/6Y08giU8ON4Ov5ePiouea67/nc933NDG/u+76wGWOMAAAAAACWcSvoAgAAAADgdkMQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADirjvv/9eNptN33//vUvXa7PZNGrUKJeu01lHjhyRzWbT22+/fdO+o0aNks1mc9lrZ+7XhQsXumydsE7FihXVp0+fgi6jUMqvz5TCxtWfKQBuPwQx4Bby8ccfy2az2f8VK1ZMZcuWVZ8+fXTs2DHL6/nmm28KPGzdTjZs2KBRo0YpKSmpoEtxuT59+jiM7Zz+5SUcWTEuXVlvYTVz5kx9/PHHBV1GkfDVV18pKipKISEh8vHxUeXKldW9e3ctW7asoEsrcPnxvXf58mWNGjXqtv9lAW59xQq6AABZjRkzRpUqVdLVq1e1ceNGffzxx1q3bp12794tb29vy+r45ptvNGPGjGx/6L1y5YqKFSs8HyGvvPKKhg0bVtBl5GrDhg0aPXq0+vTpo8DAwIIux6WeeuopRUdH2x8fPnxYI0aM0IABA9SiRQt7e5UqVW66rtzGpau4st7CaubMmSpVqlSWsNmyZUtduXJFnp6eBVNYIfP2229r6NChioqK0vDhw+Xj46NffvlFK1as0Lx589S+ffuCLvGW4MrvvcuXL2v06NGSpFatWuVDtYBrFJ6fooDbyH333adGjRpJkv7v//5PpUqV0oQJE/Tll1+qe/fuBVzddVYGQlcoVqxYoQqORU1kZKQiIyPtj3/88UeNGDFCkZGRevzxxwuwsuz92XovXbokX19fK0osMG5uboXu/V9Qrl27prFjx6pt27Zavnx5ludPnjxZAFXdmgrD9x7galyaCBQCmb+BP3TokEP7/v379fDDDysoKEje3t5q1KiRvvzyy5uub+3aterWrZvKly8vLy8vhYeH629/+5uuXLli79OnTx/NmDFDkhwuG8mU3T1i27dv13333Sd/f3/5+fmpTZs22rhxo0OfzMtQ1q9fr9jYWAUHB8vX11ddunTRqVOnHPr++OOPiomJUalSpVS8eHFVqlRJTz75ZLbb9N5776lKlSry8vLS3XffrS1btjg8n939HDabTYMHD9Znn32m6tWry9vbWxEREfrhhx9uug8zpaen6x//+IfCwsLk6+urBx54QL/99luWfps2bVL79u0VEBAgHx8fRUVFaf369Q71DR06VJJUqVIl+/4+cuSIHnroITVs2NBhfZ06dZLNZnM43ps2bZLNZtO3335rb0tKStLzzz+v8PBweXl5qWrVqpowYYIyMjIc1peRkaHJkyerdu3a8vb2VmhoqJ566imdO3fOoV/FihV1//33a926dWrcuLG8vb1VuXJlffrpp3neZ7lZsGCBIiIiVLx4cZUqVUqPP/64w+VJNxuXb7/9tpo1a6aSJUuqePHiioiIyLf7+DLH8po1azRw4ECFhISoXLlykqRff/1VAwcOVPXq1VW8eHGVLFlS3bp105EjR7Jdh6veD85s/7/+9S81btxYPj4+uuOOO9SyZUt7WKhYsaL27NmjNWvW2Pdx5pmFnO4Ru9mxk64fPz8/Px07dkydO3eWn5+fgoOD9eKLLyo9Pd2h77x58xQREaESJUrI399fdevW1ZQpU256XPK6DzLf/0uWLFGdOnXk5eWl2rVrZ3u54Lp163T33XfL29tbVapU0bvvvnvTOiTp9OnTSk5O1j333JPt8yEhIfb/zxwLN46RnPb3pk2b1KFDB91xxx3y9fVVvXr1suyf/fv3q3v37goODlbx4sVVvXp1vfzyyw59jh07pieffFKhoaH2ffDRRx9lqXXatGmqXbu2fbw0atRIc+fOtT9/4cIFPf/886pYsaK8vLwUEhKitm3batu2bXnZVVlk972XmpqqESNGKCIiQgEBAfL19VWLFi20evVqe58jR44oODhYkjR69Gj7+P3j99Wf/e4EXI1fDwOFQOYX8x133GFv27Nnj+655x6VLVtWw4YNk6+vrz7//HN17txZixYtUpcuXXJc34IFC3T58mU988wzKlmypDZv3qxp06bp999/14IFCyRdvzTr+PHjiouL0z//+c+b1rhnzx61aNFC/v7++vvf/y4PDw+9++67atWqldasWaMmTZo49H/22Wd1xx13aOTIkTpy5IgmT56swYMHa/78+ZKu/6a4Xbt2Cg4O1rBhwxQYGKgjR45o8eLFWV577ty5unDhgp566inZbDa9+eabeuihh/Tf//5XHh4euda9Zs0azZ8/X0OGDJGXl5dmzpyp9u3ba/PmzapTp85Nt3vcuHGy2Wx66aWXdPLkSU2ePFnR0dHasWOHihcvLklatWqV7rvvPkVERGjkyJFyc3PTnDlz1Lp1a61du1aNGzfWQw89pJ9//ln//ve/9c4776hUqVKSpODgYLVo0UJffPGFkpOT5e/vL2OM1q9fLzc3N61du1YPPPCApOsB283Nzf5D3+XLlxUVFaVjx47pqaeeUvny5bVhwwYNHz5cJ06c0OTJk+3b8dRTT+njjz9W3759NWTIEB0+fFjTp0/X9u3btX79eof9+Msvv+jhhx9Wv3791Lt3b3300Ufq06ePIiIiVLt27Zvus5xkvv7dd9+t8ePHKzExUVOmTNH69eu1fft2BQYG3nRcTpkyRQ888IAee+wxpaamat68eerWrZuWLl2qjh07/unacjNw4EAFBwdrxIgRunTpkiRpy5Yt2rBhg3r06KFy5crpyJEjmjVrllq1aqW9e/fKx8fHYR2uej/kdftHjx6tUaNGqVmzZhozZow8PT21adMmrVq1Su3atdPkyZP17LPPys/Pz/6De2hoaI77IC/HLlN6erpiYmLUpEkTvf3221qxYoUmTpyoKlWq6JlnnpEkxcXFqWfPnmrTpo0mTJggSdq3b5/Wr1+v5557Ltfj4cwYWLdunRYvXqyBAweqRIkSmjp1qrp27aqjR4+qZMmSkqRdu3bZ9/2oUaN07do1jRw5Mtf9kSkkJETFixfXV199pWeffVZBQUE3XSYv4uLidP/996t06dJ67rnnFBYWpn379mnp0qX2/bNz5061aNFCHh4eGjBggCpWrKhDhw7pq6++0rhx4yRJiYmJatq0qT2UBgcH69tvv1W/fv2UnJys559/XpL0/vvva8iQIXr44Yf13HPP6erVq9q5c6c2bdqkRx99VJL09NNPa+HChRo8eLBq1aqlM2fOaN26ddq3b1+WXyTlRXbfe8nJyfrggw/Us2dP9e/fXxcuXNCHH36omJgYbd68WfXr11dwcLBmzZqlZ555Rl26dNFDDz0kSapXr56kv/bdCbicAXDLmDNnjpFkVqxYYU6dOmV+++03s3DhQhMcHGy8vLzMb7/9Zu/bpk0bU7duXXP16lV7W0ZGhmnWrJmpVq2avW316tVGklm9erW97fLly1lee/z48cZms5lff/3V3jZo0CCT08eEJDNy5Ej7486dOxtPT09z6NAhe9vx48dNiRIlTMuWLbNsY3R0tMnIyLC3/+1vfzPu7u4mKSnJGGPMf/7zHyPJbNmyJcf9dfjwYSPJlCxZ0pw9e9be/sUXXxhJ5quvvrK3jRw5Msu2SDKSzI8//mhv+/XXX423t7fp0qVLjq9rzP/2a9myZU1ycrK9/fPPPzeSzJQpU4wx149JtWrVTExMjMP2Xr582VSqVMm0bdvW3vbWW28ZSebw4cMOr7VlyxYjyXzzzTfGGGN27txpJJlu3bqZJk2a2Ps98MADpkGDBvbHY8eONb6+vubnn392WN+wYcOMu7u7OXr0qDHGmLVr1xpJ5rPPPnPot2zZsiztFSpUMJLMDz/8YG87efKk8fLyMi+88EKu+yy7bZozZ44xxpjU1FQTEhJi6tSpY65cuWLvt3TpUiPJjBgxwt6W27i8cWynpqaaOnXqmNatWzu0V6hQwfTu3ftP12vM/8Zy8+bNzbVr13Ktwxhj4uPjjSTz6aefZlmHK94P2b1udtt/8OBB4+bmZrp06WLS09Md+v+xhtq1a5uoqKgsr3HjZ4ozx653795GkhkzZozDOhs0aGAiIiLsj5977jnj7++fZb/mRV7HgCTj6elpfvnlF3vbTz/9ZCSZadOm2ds6d+5svL29HT4b9+7da9zd3XMch380YsQII8n4+vqa++67z4wbN85s3bo1S7/MsXDj+//G/X3t2jVTqVIlU6FCBXPu3DmHvn88fi1btjQlSpRwqPvGPv369TOlS5c2p0+fdujTo0cPExAQYN+XDz74oKldu3au2xkQEGAGDRqUa5/sOPO9d+3aNZOSkuKw/Llz50xoaKh58skn7W2nTp3K8h2VKa/fnYAVuDQRuAVFR0crODhY4eHhevjhh+Xr66svv/zSftnT2bNntWrVKnXv3l0XLlzQ6dOndfr0aZ05c0YxMTE6ePBgrrNNZZ6pka7f03L69Gk1a9ZMxhht377d6XrT09O1fPlyde7cWZUrV7a3ly5dWo8++qjWrVun5ORkh2UGDBjgcElZixYtlJ6erl9//VWS7L9BX7p0qdLS0nJ9/UceecTht6aZl7T897//vWntkZGRioiIsD8uX768HnzwQX333XdZLpXKTq9evVSiRAn744cfflilS5fWN998I0nasWOHDh48qEcffVRnzpyxH6tLly6pTZs2+uGHH7JcJnijBg0ayM/Pz37J5Nq1a1WuXDn16tVL27Zt0+XLl2WM0bp16xwmkliwYIFatGihO+64w/66p0+fVnR0tNLT0+3rW7BggQICAtS2bVuHfhEREfLz83O47EeSatWq5fA6wcHBql69ep72d05+/PFHnTx5UgMHDnS4/6hjx46qUaOGvv766zyt549j+9y5czp//rxatGjxpy+Pyov+/fvL3d09xzrS0tJ05swZVa1aVYGBgdnW4qr3Q162f8mSJcrIyNCIESPk5ub4Y8CfmY79zxy7p59+2uFxixYtHMZPYGCgLl26pLi4OKfrcWYMREdHO0y4Uq9ePfn7+9trSU9P13fffafOnTurfPny9n41a9ZUTExMnuoZPXq05s6dqwYNGui7777Tyy+/rIiICDVs2FD79u1zevu2b9+uw4cP6/nnn88yqU/m8Tt16pR++OEHPfnkkw51/7GPMUaLFi1Sp06dZIxxeO/HxMTo/Pnz9n0WGBio33//Pcsl338UGBioTZs26fjx405vk3Tz7z1Jcnd3t08Sk5GRobNnz+ratWtq1KhRnt7jf/W7E3A1ghhwC5oxY4bi4uK0cOFCdejQQadPn5aXl5f9+V9++UXGGL366qsKDg52+Ddy5EhJud8EfvToUfXp00dBQUH2ezSioqIkSefPn3e63lOnTuny5cuqXr16ludq1qypjIyMLPdN3fjDQWaQyrwnKSoqSl27dtXo0aNVqlQpPfjgg5ozZ45SUlKyvMbN1pWbatWqZWm78847dfny5Sz36ORleZvNpqpVq9ovqzl48KAkqXfv3lmO1QcffKCUlJSb7nN3d3dFRkZq7dq1kq4HsRYtWqh58+ZKT0/Xxo0btXfvXp09e9YhIB08eFDLli3L8rqZswFmjpGDBw/q/PnzCgkJydL34sWLWcbSjftbur7P87K/c5IZOLIbQzVq1LA/fzNLly5V06ZN5e3traCgIPtlSn9mXOdVpUqVsrRduXJFI0aMsN+bV6pUKQUHByspKSnbWlz1fsjL9h86dEhubm6qVavWX952yflj5+3tbb+HJ9ON42fgwIG68847dd9996lcuXJ68skn8zzVuzNj4GZj+dSpU7py5Uq2nxPZbW9OevbsqbVr1+rcuXNavny5Hn30UW3fvl2dOnXS1atX87we6X/3TOV26XRmkMytz6lTp5SUlKT33nsvy/u+b9++kv73GfHSSy/Jz89PjRs3VrVq1TRo0CCHe1wl6c0339Tu3bsVHh6uxo0ba9SoUU79cuZm33uZPvnkE9WrV0/e3t4qWbKkgoOD9fXXX+fpPf5XvzsBV+MeMeAW1LhxY/vsUZ07d1bz5s316KOP6sCBA/Lz87OfQXnxxRdz/K1s1apVs21PT09X27ZtdfbsWb300kuqUaOGfH19dezYMfXp0+emZ2dc5cYzCJmMMZJk/2PJGzdu1FdffaXvvvtOTz75pCZOnKiNGzfKz88vz+sqSJn786233lL9+vWz7fPHbclJ8+bNNW7cOF29elVr167Vyy+/rMDAQNWpU0dr166136/yxyCWkZGhtm3b6u9//3u267zzzjvt/UJCQvTZZ59l2+/GH5pv1f2deb9cy5YtNXPmTJUuXVoeHh6aM2eOw6QCrvbHMzCZnn32Wc2ZM0fPP/+8IiMjFRAQIJvNph49emT7HnPF+6Ggtt9ZOW3rH4WEhGjHjh367rvv9O233+rbb7/VnDlz1KtXL33yySc5LufsPrB6LPv7+6tt27Zq27atPDw89Mknn2jTpk2KiorK8WxkXs7M/xmZ4/Dxxx9X7969s+2TeV9VzZo1deDAAS1dulTLli3TokWLNHPmTI0YMcI+TXz37t3VokUL/ec//9Hy5cv11ltvacKECVq8eLHuu+++m9Zzs+896foEM3369FHnzp01dOhQhYSEyN3dXePHj88ymVVu2/xnvjuB/EAQA25xmV8y9957r6ZPn65hw4bZL//z8PBw+FtHebFr1y79/PPP+uSTT9SrVy97e3aXAOX1MqXg4GD5+PjowIEDWZ7bv3+/3NzcFB4e7lSdmZo2baqmTZtq3Lhxmjt3rh577DHNmzdP//d///en1nejzDNWf/Tzzz/Lx8cnSwDJy/LGGP3yyy/2H2AyL3vy9/e/6bHKbX+3aNFCqamp+ve//61jx47ZA1fLli3tQezOO+90mECgSpUqunjx4k1ft0qVKlqxYoXuueeebEOFFSpUqCBJOnDggFq3bu3w3IEDB+zPSznvp0WLFsnb21vfffedw2/S58yZkw8V527hwoXq3bu3Jk6caG+7evXqX/5j3bm9H/K6/VWqVFFGRob27t2b4y8HpLy//505ds7w9PRUp06d1KlTJ2VkZGjgwIF699139eqrr+b4w7Krx0DmbIPZfU5k93nnjEaNGumTTz7RiRMnJP3vLOiNY+TGM4qZnym7d+/O8b2d+R2xe/fuHF8/ODhYJUqUUHp6ep6+R3x9ffXII4/okUceUWpqqh566CGNGzdOw4cPt1+SWrp0aQ0cOFADBw7UyZMn1bBhQ40bNy5PQeyPsvvek66/rypXrqzFixc7jM/Ms1mZchq7f+W7E8gPXJoIFAKtWrVS48aNNXnyZF29elUhISFq1aqV3n33XfuX+B/ldkld5m+A//gbX2NMttNCZ/49pJv98Oju7q527drpiy++cJh6OTExUXPnzlXz5s3l7++f6zpudO7cuSy/lc78oTG7yxP/rPj4eId7C3777Td98cUXateuXZ5+c//pp5/qwoUL9scLFy7UiRMn7D94REREqEqVKnr77bd18eLFLMv/8Vjltr+bNGkiDw8PTZgwQUFBQfbZCVu0aKGNGzdqzZo1DmfDpOu/oY6Pj9d3332XZX1JSUm6du2avV96errGjh2bpd+1a9f+cnjIi0aNGikkJESzZ892OL7ffvut9u3b5zDbXU77yd3dXTabzeEMwpEjR7RkyZJ8rT077u7uWcbvtGnT/vTZjby8H/K6/Z07d5abm5vGjBmT5ezcH1/D19c3T8femWOXV2fOnHF47ObmZv/lRm7vf1ePAXd3d8XExGjJkiU6evSovX3fvn3Zvq9udPnyZcXHx2f7XOafmci8xDEzYP3xz2ekp6frvffec1iuYcOGqlSpkiZPnpzl+GQev+DgYLVs2VIfffSRQ91/7OPu7q6uXbtq0aJF2Qa2P3423Xg8PD09VatWLRljlJaWpvT09CyXBoaEhKhMmTJ/+vP6xu+9zJr/uA3S9Wn8b9zHmbOS3rh//sp3J5AfOCMGFBJDhw5Vt27d9PHHH+vpp5/WjBkz1Lx5c9WtW1f9+/dX5cqVlZiYqPj4eP3+++/66aefsl1PjRo1VKVKFb344os6duyY/P39tWjRomzv78mcxGLIkCGKiYmRu7u7evToke16X3vtNcXFxal58+YaOHCgihUrpnfffVcpKSl68803nd7eTz75RDNnzlSXLl1UpUoVXbhwQe+//778/f3VoUMHp9eXkzp16igmJsZh+npJ9sttbiYoKEjNmzdX3759lZiYqMmTJ6tq1arq37+/pOs/QH7wwQe67777VLt2bfXt21dly5bVsWPHtHr1avn7++urr76S9L/9/fLLL6tHjx7y8PBQp06d5OvrKx8fH0VERGjjxo32vyEmXT8jdunSJV26dClLEBs6dKi+/PJL3X///fbp5S9duqRdu3Zp4cKFOnLkiEqVKqWoqCg99dRTGj9+vHbs2KF27drJw8NDBw8e1IIFCzRlyhQ9/PDDLtnfOckMmX379lVUVJR69uxpnwK9YsWK+tvf/mbvm9O47NixoyZNmqT27dvr0Ucf1cmTJzVjxgxVrVpVO3fuzNf6b3T//ffrn//8pwICAlSrVi3Fx8drxYoV9inRnZWX90Net79q1ap6+eWXNXbsWLVo0UIPPfSQvLy8tGXLFpUpU0bjx4+XdH0/z5o1S6+99pqqVq2qkJCQLGe8JOeOXV793//9n86ePavWrVurXLly+vXXXzVt2jTVr19fNWvWzHG5/BgDo0eP1rJly9SiRQsNHDhQ165ds/9NrZut8/Lly2rWrJmaNm2q9u3bKzw8XElJSVqyZInWrl2rzp07q0GDBpKk2rVrq2nTpho+fLjOnj2roKAgzZs3z/4Lk0xubm6aNWuWOnXqpPr166tv374qXbq09u/frz179tgD4tSpU9W8eXM1bNhQAwYMUKVKlXTkyBF9/fXX2rFjhyTpjTfe0OrVq9WkSRP1799ftWrV0tmzZ7Vt2zatWLFCZ8+elSS1a9dOYWFhuueeexQaGqp9+/Zp+vTp6tixo0qUKKGkpCSVK1dODz/8sO666y75+flpxYoV2rJli8NZYWfd+L13//33a/HixerSpYs6duyow4cPa/bs2apVq5bDL7qKFy+uWrVqaf78+brzzjsVFBSkOnXqqE6dOn/6uxPIF1ZO0Qggd5nT+GY3RXV6erqpUqWKqVKlin1K50OHDplevXqZsLAw4+HhYcqWLWvuv/9+s3DhQvty2U1fv3fvXhMdHW38/PxMqVKlTP/+/e3TNv9xeu5r166ZZ5991gQHBxubzeYwVbOymRp427ZtJiYmxvj5+RkfHx9z7733mg0bNuRpG2+sc9u2baZnz56mfPnyxsvLy4SEhJj777/fYar5zOnr33rrrSz768b6cpq+ftCgQeZf//qXqVatmvHy8jINGjRw2Fc5yaz33//+txk+fLgJCQkxxYsXNx07dswyXbQxxmzfvt089NBDpmTJksbLy8tUqFDBdO/e3axcudKh39ixY03ZsmWNm5tblqmshw4daiSZCRMmOCxTtWpVI8nhTwdkunDhghk+fLipWrWq8fT0NKVKlTLNmjUzb7/9tklNTXXo+95775mIiAhTvHhxU6JECVO3bl3z97//3Rw/ftzep0KFCqZjx45ZXicqKirbqc5zkt108MYYM3/+fNOgQQPj5eVlgoKCzGOPPWZ+//13hz65jcsPP/zQfixr1Khh5syZk+2xd+X09dm9X8+dO2f69u1rSpUqZfz8/ExMTIzZv39/ltd15fvBme03xpiPPvrIvq/vuOMOExUVZeLi4uzPJyQkmI4dO5oSJUoYSfbjm91nijF5O3a9e/c2vr6+WWq5scaFCxeadu3amZCQEOPp6WnKly9vnnrqKXPixIksy94or/sg8/1/o+zGxpo1a0xERITx9PQ0lStXNrNnz85xv/5RWlqaef/9903nzp1NhQoVjJeXl/Hx8TENGjQwb731Vpap2A8dOmSio6ONl5eXCQ0NNf/4xz9MXFxctvt73bp1pm3btqZEiRLG19fX1KtXz2HafWOM2b17t+nSpYsJDAw03t7epnr16ubVV1916JOYmGgGDRpkwsPDjYeHhwkLCzNt2rQx7733nr3Pu+++a1q2bGn//KpSpYoZOnSoOX/+vDHGmJSUFDN06FBz11132eu56667zMyZM3PdP8Y4972XkZFhXn/9dfu+bNCggVm6dKnp3bu3qVChgsOyGzZssB+zG78P8vLdCVjBZswtcDc7ABQAm82mQYMGafr06QVdCgAAuM1wjxgAAAAAWIwgBgAAAAAWI4gBAAAAgMWYNRHAbYtbZAEAQEHhjBgAAAAAWIwgBgAAAAAW49JEF8jIyNDx48dVokQJ+x9ZBQAAAHD7McbowoULKlOmjNzccj7vRRBzgePHjys8PLygywAAAABwi/jtt99Urly5HJ8niLlAiRIlJF3f2f7+/gVcDbKTlpam5cuXq127dvLw8CjoclAIMGbgLMYMnMWYgbMYM4VDcnKywsPD7RkhJwQxF8i8HNHf358gdotKS0uTj4+P/P39+eBCnjBm4CzGDJzFmIGzGDOFy81uWWKyDgAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYoUuiM2YMUMVK1aUt7e3mjRpos2bN+faf8GCBapRo4a8vb1Vt25dffPNNzn2ffrpp2Wz2TR58mQXVw0AAAAA/1Oogtj8+fMVGxurkSNHatu2bbrrrrsUExOjkydPZtt/w4YN6tmzp/r166ft27erc+fO6ty5s3bv3p2l73/+8x9t3LhRZcqUye/NAAAAAHCbK1RBbNKkSerfv7/69u2rWrVqafbs2fLx8dFHH32Ubf8pU6aoffv2Gjp0qGrWrKmxY8eqYcOGmj59ukO/Y8eO6dlnn9Vnn30mDw8PKzYFAAAAwG2sWEEXkFepqanaunWrhg8fbm9zc3NTdHS04uPjs10mPj5esbGxDm0xMTFasmSJ/XFGRoaeeOIJDR06VLVr185TLSkpKUpJSbE/Tk5OliSlpaUpLS0tr5sEC2UeF44P8ooxA2cxZuAsxgycxZgpHPJ6fApNEDt9+rTS09MVGhrq0B4aGqr9+/dnu0xCQkK2/RMSEuyPJ0yYoGLFimnIkCF5rmX8+PEaPXp0lvbly5fLx8cnz+uB9eLi4gq6BBQyjBk4izEDZzFm4CzGzK3t8uXLeepXaIJYfti6daumTJmibdu2yWaz5Xm54cOHO5xpS05OVnh4uNq1ayd/f//8KBV/UVpamuLi4tS2bVsuP0WeMGbgLMYMnMWYgbMYM4VD5tVyN1NoglipUqXk7u6uxMREh/bExESFhYVlu0xYWFiu/deuXauTJ0+qfPny9ufT09P1wgsvaPLkyTpy5Ei26/Xy8pKXl1eWdg8PD94UtziOEZzFmIGzGDNwFmMGzmLM3NryemwKzWQdnp6eioiI0MqVK+1tGRkZWrlypSIjI7NdJjIy0qG/dP1Ubmb/J554Qjt37tSOHTvs/8qUKaOhQ4fqu+++y7+NAQAAAHBbKzRnxCQpNjZWvXv3VqNGjdS4cWNNnjxZly5dUt++fSVJvXr1UtmyZTV+/HhJ0nPPPaeoqChNnDhRHTt21Lx58/Tjjz/qvffekySVLFlSJUuWdHgNDw8PhYWFqXr16tZuHAAAAIDbRqEKYo888ohOnTqlESNGKCEhQfXr19eyZcvsE3IcPXpUbm7/O8nXrFkzzZ07V6+88or+8Y9/qFq1alqyZInq1KlTUJsAAAAAAIUriEnS4MGDNXjw4Gyf+/7777O0devWTd26dcvz+nO6LwwAAAAAXKXQ3CMGAAAAAEUFQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALBYoQtiM2bMUMWKFeXt7a0mTZpo8+bNufZfsGCBatSoIW9vb9WtW1fffPON/bm0tDS99NJLqlu3rnx9fVWmTBn16tVLx48fz+/NAAAAAHAbK1RBbP78+YqNjdXIkSO1bds23XXXXYqJidHJkyez7b9hwwb17NlT/fr10/bt29W5c2d17txZu3fvliRdvnxZ27Zt06uvvqpt27Zp8eLFOnDggB544AErNwsAAADAbaZQBbFJkyapf//+6tu3r2rVqqXZs2fLx8dHH330Ubb9p0yZovbt22vo0KGqWbOmxo4dq4YNG2r69OmSpICAAMXFxal79+6qXr26mjZtqunTp2vr1q06evSolZsGAAAA4DZSrKALyKvU1FRt3bpVw4cPt7e5ubkpOjpa8fHx2S4THx+v2NhYh7aYmBgtWbIkx9c5f/68bDabAgMDc+yTkpKilJQU++Pk5GRJ1y91TEtLy8PWwGqZx4Xjg7xizMBZjBk4izEDZzFmCoe8Hp9CE8ROnz6t9PR0hYaGOrSHhoZq//792S6TkJCQbf+EhIRs+1+9elUvvfSSevbsKX9//xxrGT9+vEaPHp2lffny5fLx8bnZpqAAxcXFFXQJKGQYM3AWYwbOYszAWYyZW9vly5fz1K/QBLH8lpaWpu7du8sYo1mzZuXad/jw4Q5n2pKTkxUeHq527drlGuBQcNLS0hQXF6e2bdvKw8OjoMtBIcCYgbMYM3AWYwbOYswUDplXy91MoQlipUqVkru7uxITEx3aExMTFRYWlu0yYWFheeqfGcJ+/fVXrVq16qZhysvLS15eXlnaPTw8eFPc4jhGcBZjBs5izMBZjBk4izFza8vrsSk0k3V4enoqIiJCK1eutLdlZGRo5cqVioyMzHaZyMhIh/7S9VO5f+yfGcIOHjyoFStWqGTJkvmzAQAAAADw/xWaM2KSFBsbq969e6tRo0Zq3LixJk+erEuXLqlv376SpF69eqls2bIaP368JOm5555TVFSUJk6cqI4dO2revHn68ccf9d5770m6HsIefvhhbdu2TUuXLlV6err9/rGgoCB5enoWzIYCAAAAKNIKVRB75JFHdOrUKY0YMUIJCQmqX7++li1bZp+Q4+jRo3Jz+99JvmbNmmnu3Ll65ZVX9I9//EPVqlXTkiVLVKdOHUnSsWPH9OWXX0qS6tev7/Baq1evVqtWrSzZLgAAAAC3l0IVxCRp8ODBGjx4cLbPff/991naunXrpm7dumXbv2LFijLGuLI8AAAAALipQnOPGAAAAAAUFQQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAi/3pIJaamqoDBw7o2rVrrqwHAAAAAIo8p4PY5cuX1a9fP/n4+Kh27do6evSoJOnZZ5/VG2+84fICAQAAAKCocTqIDR8+XD/99JO+//57eXt729ujo6M1f/58lxYHAAAAAEVRMWcXWLJkiebPn6+mTZvKZrPZ22vXrq1Dhw65tDgAAAAAKIqcPiN26tQphYSEZGm/dOmSQzADAAAAAGTP6SDWqFEjff311/bHmeHrgw8+UGRkpOsqAwAAAIAiyulLE19//XXdd9992rt3r65du6YpU6Zo79692rBhg9asWZMfNQIAAABAkeL0GbHmzZtrx44dunbtmurWravly5crJCRE8fHxioiIyI8aAQAAAKBIcfqMmCRVqVJF77//vqtrAQAAAIDbgtNnxNzd3XXy5Mks7WfOnJG7u7tLigIAAACAoszpIGaMybY9JSVFnp6ef7kgAAAAACjq8nxp4tSpUyVdnyXxgw8+kJ+fn/259PR0/fDDD6pRo4brKwQAAACAIibPQeydd96RdP2M2OzZsx0uQ/T09FTFihU1e/Zs11cIAAAAAEVMnoPY4cOHJUn33nuvFi9erDvuuCPfigIAAACAoszpWRNXr16dH3UAAAAAwG3jT01f//vvv+vLL7/U0aNHlZqa6vDcpEmTXFIYAAAAABRVTgexlStX6oEHHlDlypW1f/9+1alTR0eOHJExRg0bNsyPGgEAAACgSHF6+vrhw4frxRdf1K5du+Tt7a1Fixbpt99+U1RUlLp165YfNQIAAABAkeJ0ENu3b5969eolSSpWrJiuXLkiPz8/jRkzRhMmTHB5gQAAAABQ1DgdxHx9fe33hZUuXVqHDh2yP3f69GnXVQYAAAAARZTT94g1bdpU69atU82aNdWhQwe98MIL2rVrlxYvXqymTZvmR40AAAAAUKQ4HcQmTZqkixcvSpJGjx6tixcvav78+apWrRozJgIAAABAHjgdxCpXrmz/f19fX82ePdulBQEAAABAUef0PWI5Wbx4serVq+eq1QEAAABAkeVUEHv33Xf18MMP69FHH9WmTZskSatWrVKDBg30xBNP6J577smXIgEAAACgKMlzEHvjjTf07LPP6siRI/ryyy/VunVrvf7663rsscf0yCOP6Pfff9esWbPys1YAAAAAKBLyfI/YnDlz9P7776t3795au3atoqKitGHDBv3yyy/y9fXNzxoBAAAAoEjJ8xmxo0ePqnXr1pKkFi1ayMPDQ6NHjyaEAQAAAICT8hzEUlJS5O3tbX/s6empoKCgfCkKAAAAAIoyp6avf/XVV+Xj4yNJSk1N1WuvvaaAgACHPvwtMQAAAADIXZ6DWMuWLXXgwAH742bNmum///2vQx+bzea6ygAAAACgiMpzEPv+++/zsQwAAAAAuH247A86AwAAAADyhiAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWMzpILZs2TKtW7fO/njGjBmqX7++Hn30UZ07d86lxQEAAABAUeR0EBs6dKiSk5MlSbt27dILL7ygDh066PDhw4qNjXV5gQAAAABQ1OT574hlOnz4sGrVqiVJWrRoke6//369/vrr2rZtmzp06ODyAgEAAACgqHH6jJinp6cuX74sSVqxYoXatWsnSQoKCrKfKQMAAAAA5MzpINa8eXPFxsZq7Nix2rx5szp27ChJ+vnnn1WuXDmXF3ijGTNmqGLFivL29laTJk20efPmXPsvWLBANWrUkLe3t+rWratvvvnG4XljjEaMGKHSpUurePHiio6O1sGDB/NzEwAAAADc5pwOYtOnT1exYsW0cOFCzZo1S2XLlpUkffvtt2rfvr3LC/yj+fPnKzY2ViNHjtS2bdt01113KSYmRidPnsy2/4YNG9SzZ0/169dP27dvV+fOndW5c2ft3r3b3ufNN9/U1KlTNXv2bG3atEm+vr6KiYnR1atX83VbAAAAANy+nA5i5cuX19KlS/XTTz+pX79+9vZ33nlHU6dOdWlxN5o0aZL69++vvn37qlatWpo9e7Z8fHz00UcfZdt/ypQpat++vYYOHaqaNWtq7NixatiwoaZPny7p+tmwyZMn65VXXtGDDz6oevXq6dNPP9Xx48e1ZMmSfN0WAAAAALcvpyfr2LZtmzw8PFS3bl1J0hdffKE5c+aoVq1aGjVqlDw9PV1epCSlpqZq69atGj58uL3Nzc1N0dHRio+Pz3aZ+Pj4LDM5xsTE2EPW4cOHlZCQoOjoaPvzAQEBatKkieLj49WjR49s15uSkqKUlBT748x749LS0pSWlvantg/5K/O4cHyQV4wZOIsxA2cxZuAsxkzhkNfj43QQe+qppzRs2DDVrVtX//3vf9WjRw916dJFCxYs0OXLlzV58mRnV5knp0+fVnp6ukJDQx3aQ0NDtX///myXSUhIyLZ/QkKC/fnMtpz6ZGf8+PEaPXp0lvbly5fLx8fn5huDAhMXF1fQJaCQYczAWYwZOIsxA2cxZm5tmRMb3ozTQeznn39W/fr1JV2fCKNly5aaO3eu1q9frx49euRbELuVDB8+3OFMW3JyssLDw9WuXTv5+/sXYGXISVpamuLi4tS2bVt5eHgUdDkoBBgzcBZjBs5izMBZjJnCIa8zyTsdxIwxysjIkHR9+vr7779fkhQeHq7Tp087u7o8K1WqlNzd3ZWYmOjQnpiYqLCwsGyXCQsLy7V/5n8TExNVunRphz6ZYTM7Xl5e8vLyytLu4eHBm+IWxzGCsxgzcBZjBs5izMBZjJlbW16PjdOTdTRq1Eivvfaa/vnPf2rNmjX26esPHz6c5RI/V/L09FRERIRWrlxpb8vIyNDKlSsVGRmZ7TKRkZEO/aXrp3Iz+1eqVElhYWEOfZKTk7Vp06Yc1wkAAAAAf5XTZ8QmT56sxx57TEuWLNHLL7+sqlWrSpIWLlyoZs2aubzAP4qNjVXv3r3VqFEjNW7cWJMnT9alS5fUt29fSVKvXr1UtmxZjR8/XpL03HPPKSoqShMnTlTHjh01b948/fjjj3rvvfckSTabTc8//7xee+01VatWTZUqVdKrr76qMmXKqHPnzvm6LQAAAABuX04HsXr16mnXrl1Z2t966y25u7u7pKicPPLIIzp16pRGjBihhIQE1a9fX8uWLbOfiTt69Kjc3P53kq9Zs2aaO3euXnnlFf3jH/9QtWrVtGTJEtWpU8fe5+9//7suXbqkAQMGKCkpSc2bN9eyZcvk7e2dr9sCAAAA4PbldBCTpKSkJC1cuFCHDh3S0KFDFRQUpL179yo0NNT+B57zy+DBgzV48OBsn/v++++ztHXr1k3dunXLcX02m01jxozRmDFjXFUiAAAAAOTK6SC2c+dOtWnTRoGBgTpy5Ij69++voKAgLV68WEePHtWnn36aH3UCAAAAQJHh9GQdsbGx6tu3rw4ePOhw+V6HDh30ww8/uLQ4AAAAACiKnA5iW7Zs0VNPPZWlvWzZsrn+EWQAAAAAwHVOBzEvL69s/0jZzz//rODgYJcUBQAAAABFmdNB7IEHHtCYMWOUlpYm6fpkF0ePHtVLL72krl27urxAAAAAAChqnA5iEydO1MWLFxUSEqIrV64oKipKVatWVYkSJTRu3Lj8qBEAAAAAihSnZ00MCAhQXFyc1q9fr59++kkXL15Uw4YNFR0dnR/1AQAAAECR86f+jpgk3XPPPbrnnntcWQsAAAAA3BacvjRxyJAhmjp1apb26dOn6/nnn3dFTQAAAABQpDkdxBYtWpTtmbBmzZpp4cKFLikKAAAAAIoyp4PYmTNnFBAQkKXd399fp0+fdklRAAAAAFCUOR3EqlatqmXLlmVp//bbb1W5cmWXFAUAAAAARZnTk3XExsZq8ODBOnXqlFq3bi1JWrlypSZOnKjJkye7uj4AAAAAKHKcDmJPPvmkUlJSNG7cOI0dO1aSVLFiRc2aNUu9evVyeYEAAAAAUNT8qenrn3nmGT3zzDM6deqUihcvLj8/P1fXBQAAAABFltNB7PDhw7p27ZqqVaum4OBge/vBgwfl4eGhihUrurI+AAAAAChynJ6so0+fPtqwYUOW9k2bNqlPnz6uqAkAAAAAijSng9j27duz/TtiTZs21Y4dO1xREwAAAAAUaU4HMZvNpgsXLmRpP3/+vNLT011SFAAAAAAUZU4HsZYtW2r8+PEOoSs9PV3jx49X8+bNXVocAAAAABRFTk/WMWHCBLVs2VLVq1dXixYtJElr165VcnKyVq1a5fICAQAAAKCocfqMWK1atbRz5051795dJ0+e1IULF9SrVy/t379fderUyY8aAQAAAKBI+VN/R6xMmTJ6/fXXXV0LAAAAANwWnA5iP/zwQ67Pt2zZ8k8XAwAAAAC3A6eDWKtWrbK02Ww2+/8zcyIAAAAA5M7pe8TOnTvn8O/kyZNatmyZ7r77bi1fvjw/agQAAACAIsXpM2IBAQFZ2tq2bStPT0/FxsZq69atLikMAAAAAIoqp8+I5SQ0NFQHDhxw1eoAAAAAoMhy+ozYzp07HR4bY3TixAm98cYbql+/vqvqAgAAAIAiy+kgVr9+fdlsNhljHNqbNm2qjz76yGWFAQAAAEBR5XQQO3z4sMNjNzc3BQcHy9vb22VFAQAAAEBR5nQQq1ChQn7UAQAAAAC3jTxP1hEfH6+lS5c6tH366aeqVKmSQkJCNGDAAKWkpLi8QAAAAAAoavIcxMaMGaM9e/bYH+/atUv9+vVTdHS0hg0bpq+++krjx4/PlyIBAAAAoCjJcxDbsWOH2rRpY388b948NWnSRO+//75iY2M1depUff755/lSJAAAAAAUJXkOYufOnVNoaKj98Zo1a3TffffZH99999367bffXFsdAAAAABRBeQ5ioaGh9hkTU1NTtW3bNjVt2tT+/IULF+Th4eH6CgEAAACgiMlzEOvQoYOGDRumtWvXavjw4fLx8VGLFi3sz+/cuVNVqlTJlyIBAAAAoCjJ8/T1Y8eO1UMPPaSoqCj5+fnpk08+kaenp/35jz76SO3atcuXIgEAAACgKMlzECtVqpR++OEHnT9/Xn5+fnJ3d3d4fsGCBfLz83N5gQAAAABQ1Dj9B50DAgKybQ8KCvrLxQAAAADA7SDP94gBAAAAAFyDIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGCxQhPEzp49q8cee0z+/v4KDAxUv379dPHixVyXuXr1qgYNGqSSJUvKz89PXbt2VWJiov35n376ST179lR4eLiKFy+umjVrasqUKfm9KQAAAABuc4UmiD322GPas2eP4uLitHTpUv3www8aMGBArsv87W9/01dffaUFCxZozZo1On78uB566CH781u3blVISIj+9a9/ac+ePXr55Zc1fPhwTZ8+Pb83BwAAAMBtrFhBF5AX+/bt07Jly7RlyxY1atRIkjRt2jR16NBBb7/9tsqUKZNlmfPnz+vDDz/U3Llz1bp1a0nSnDlzVLNmTW3cuFFNmzbVk08+6bBM5cqVFR8fr8WLF2vw4MH5v2EAAAAAbkuFIojFx8crMDDQHsIkKTo6Wm5ubtq0aZO6dOmSZZmtW7cqLS1N0dHR9rYaNWqofPnyio+PV9OmTbN9rfPnzysoKCjXelJSUpSSkmJ/nJycLElKS0tTWlqaU9sGa2QeF44P8ooxA2cxZuAsxgycxZgpHPJ6fApFEEtISFBISIhDW7FixRQUFKSEhIQcl/H09FRgYKBDe2hoaI7LbNiwQfPnz9fXX3+daz3jx4/X6NGjs7QvX75cPj4+uS6LghUXF1fQJaCQYczAWYwZOIsxA2cxZm5tly9fzlO/Ag1iw4YN04QJE3Lts2/fPktq2b17tx588EGNHDlS7dq1y7Xv8OHDFRsba3+cnJys8PBwtWvXTv7+/vldKv6EtLQ0xcXFqW3btvLw8CjoclAIMGbgLMYMnMWYgbMYM4VD5tVyN1OgQeyFF15Qnz59cu1TuXJlhYWF6eTJkw7t165d09mzZxUWFpbtcmFhYUpNTVVSUpLDWbHExMQsy+zdu1dt2rTRgAED9Morr9y0bi8vL3l5eWVp9/Dw4E1xi+MYwVmMGTiLMQNnMWbgLMbMrS2vx6ZAg1hwcLCCg4Nv2i8yMlJJSUnaunWrIiIiJEmrVq1SRkaGmjRpku0yERER8vDw0MqVK9W1a1dJ0oEDB3T06FFFRkba++3Zs0etW7dW7969NW7cOBdsFQAAAADkrlBMX1+zZk21b99e/fv31+bNm7V+/XoNHjxYPXr0sM+YeOzYMdWoUUObN2+WJAUEBKhfv36KjY3V6tWrtXXrVvXt21eRkZH2iTp2796te++9V+3atVNsbKwSEhKUkJCgU6dOFdi2AgAAACj6CsVkHZL02WefafDgwWrTpo3c3NzUtWtXTZ061f58WlqaDhw44HBz3DvvvGPvm5KSopiYGM2cOdP+/MKFC3Xq1Cn961//0r/+9S97e4UKFXTkyBFLtgsAAADA7afQBLGgoCDNnTs3x+crVqwoY4xDm7e3t2bMmKEZM2Zku8yoUaM0atQoV5YJAAAAADdVKC5NBAAAAICihCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYrNAEsbNnz+qxxx6Tv7+/AgMD1a9fP128eDHXZa5evapBgwapZMmS8vPzU9euXZWYmJht3zNnzqhcuXKy2WxKSkrKhy0AAAAAgOsKTRB77LHHtGfPHsXFxWnp0qX64YcfNGDAgFyX+dvf/qavvvpKCxYs0Jo1a3T8+HE99NBD2fbt16+f6tWrlx+lAwAAAICDQhHE9u3bp2XLlumDDz5QkyZN1Lx5c02bNk3z5s3T8ePHs13m/Pnz+vDDDzVp0iS1bt1aERERmjNnjjZs2KCNGzc69J01a5aSkpL04osvWrE5AAAAAG5zxQq6gLyIj49XYGCgGjVqZG+Ljo6Wm5ubNm3apC5dumRZZuvWrUpLS1N0dLS9rUaNGipfvrzi4+PVtGlTSdLevXs1ZswYbdq0Sf/973/zVE9KSopSUlLsj5OTkyVJaWlpSktL+1PbiPyVeVw4PsgrxgycxZiBsxgzcBZjpnDI6/EpFEEsISFBISEhDm3FihVTUFCQEhISclzG09NTgYGBDu2hoaH2ZVJSUtSzZ0+99dZbKl++fJ6D2Pjx4zV69Ogs7cuXL5ePj0+e1oGCERcXV9AloJBhzMBZjBk4izEDZzFmbm2XL1/OU78CDWLDhg3ThAkTcu2zb9++fHv94cOHq2bNmnr88cedXi42Ntb+ODk5WeHh4WrXrp38/f1dXSZcIC0tTXFxcWrbtq08PDwKuhwUAowZOIsxA2cxZuAsxkzhkHm13M0UaBB74YUX1KdPn1z7VK5cWWFhYTp58qRD+7Vr13T27FmFhYVlu1xYWJhSU1OVlJTkcFYsMTHRvsyqVau0a9cuLVy4UJJkjJEklSpVSi+//HK2Z70kycvLS15eXlnaPTw8eFPc4jhGcBZjBs5izMBZjBk4izFza8vrsSnQIBYcHKzg4OCb9ouMjFRSUpK2bt2qiIgISddDVEZGhpo0aZLtMhEREfLw8NDKlSvVtWtXSdKBAwd09OhRRUZGSpIWLVqkK1eu2JfZsmWLnnzySa1du1ZVqlT5q5sHAAAAANkqFPeI1axZU+3bt1f//v01e/ZspaWlafDgwerRo4fKlCkjSTp27JjatGmjTz/9VI0bN1ZAQID69eun2NhYBQUFyd/fX88++6wiIyPtE3XcGLZOnz5tf70b7y0DAAAAAFcpFEFMkj777DMNHjxYbdq0kZubm7p27aqpU6fan09LS9OBAwccbo5755137H1TUlIUExOjmTNnFkT5AAAAAGBXaIJYUFCQ5s6dm+PzFStWtN/jlcnb21szZszQjBkz8vQarVq1yrIOAAAAAHC1QvEHnQEAAACgKCGIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGCxYgVdQFFgjJEkJScnF3AlyElaWpouX76s5ORkeXh4FHQ5KAQYM3AWYwbOYszAWYyZwiEzE2RmhJwQxFzgwoULkqTw8PACrgQAAADAreDChQsKCAjI8XmbuVlUw01lZGTo+PHjKlGihGw2W0GXg2wkJycrPDxcv/32m/z9/Qu6HBQCjBk4izEDZzFm4CzGTOFgjNGFCxdUpkwZubnlfCcYZ8RcwM3NTeXKlSvoMpAH/v7+fHDBKYwZOIsxA2cxZuAsxsytL7czYZmYrAMAAAAALEYQAwAAAACLEcRwW/Dy8tLIkSPl5eVV0KWgkGDMwFmMGTiLMQNnMWaKFibrAAAAAACLcUYMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDEXG2bNn9dhjj8nf31+BgYHq16+fLl68mOsyV69e1aBBg1SyZEn5+fmpa9euSkxMzLbvmTNnVK5cOdlsNiUlJeXDFsBK+TFefvrpJ/Xs2VPh4eEqXry4atasqSlTpuT3piAfzZgxQxUrVpS3t7eaNGmizZs359p/wYIFqlGjhry9vVW3bl198803Ds8bYzRixAiVLl1axYsXV3R0tA4ePJifmwALuXK8pKWl6aWXXlLdunXl6+urMmXKqFevXjp+/Hh+bwYs5OrPmD96+umnZbPZNHnyZBdXDZcxQBHRvn17c9ddd5mNGzeatWvXmqpVq5qePXvmuszTTz9twsPDzcqVK82PP/5omjZtapo1a5Zt3wcffNDcd999RpI5d+5cPmwBrJQf4+XDDz80Q4YMMd9//705dOiQ+ec//2mKFy9upk2blt+bg3wwb9484+npaT766COzZ88e079/fxMYGGgSExOz7b9+/Xrj7u5u3nzzTbN3717zyiuvGA8PD7Nr1y57nzfeeMMEBASYJUuWmJ9++sk88MADplKlSubKlStWbRbyiavHS1JSkomOjjbz5883+/fvN/Hx8aZx48YmIiLCys1CPsqPz5hMixcvNnfddZcpU6aMeeedd/J5S/BnEcRQJOzdu9dIMlu2bLG3ffvtt8Zms5ljx45lu0xSUpLx8PAwCxYssLft27fPSDLx8fEOfWfOnGmioqLMypUrCWJFQH6Plz8aOHCguffee11XPCzTuHFjM2jQIPvj9PR0U6ZMGTN+/Phs+3fv3t107NjRoa1JkybmqaeeMsYYk5GRYcLCwsxbb71lfz4pKcl4eXmZf//73/mwBbCSq8dLdjZv3mwkmV9//dU1RaNA5deY+f33303ZsmXN7t27TYUKFQhitzAuTUSREB8fr8DAQDVq1MjeFh0dLTc3N23atCnbZbZu3aq0tDRFR0fb22rUqKHy5csrPj7e3rZ3716NGTNGn376qdzceMsUBfk5Xm50/vx5BQUFua54WCI1NVVbt251ON5ubm6Kjo7O8XjHx8c79JekmJgYe//Dhw8rISHBoU9AQICaNGmS6xjCrS8/xkt2zp8/L5vNpsDAQJfUjYKTX2MmIyNDTzzxhIYOHaratWvnT/FwGX6qRJGQkJCgkJAQh7ZixYopKChICQkJOS7j6emZ5QstNDTUvkxKSop69uypt956S+XLl8+X2mG9/BovN9qwYYPmz5+vAQMGuKRuWOf06dNKT09XaGioQ3tuxzshISHX/pn/dWadKBzyY7zc6OrVq3rppZfUs2dP+fv7u6ZwFJj8GjMTJkxQsWLFNGTIENcXDZcjiOGWNmzYMNlstlz/7d+/P99ef/jw4apZs6Yef/zxfHsNuE5Bj5c/2r17tx588EGNHDlS7dq1s+Q1ARRNaWlp6t69u4wxmjVrVkGXg1vU1q1bNWXKFH388cey2WwFXQ7yoFhBFwDk5oUXXlCfPn1y7VO5cmWFhYXp5MmTDu3Xrl3T2bNnFRYWlu1yYWFhSk1NVVJSksNZjsTERPsyq1at0q5du7Rw4UJJ12c8k6RSpUrp5Zdf1ujRo//kliE/FPR4ybR37161adNGAwYM0CuvvPKntgUFq1SpUnJ3d88yi2p2xztTWFhYrv0z/5uYmKjSpUs79Klfv74Lq4fV8mO8ZMoMYb/++qtWrVrF2bAiIj/GzNq1a3Xy5EmHK3jS09P1wgsvaPLkyTpy5IhrNwJ/GWfEcEsLDg5WjRo1cv3n6empyMhIJSUlaevWrfZlV61apYyMDDVp0iTbdUdERMjDw0MrV660tx04cEBHjx5VZGSkJGnRokX66aeftGPHDu3YsUMffPCBpOsfdoMGDcrHLcefUdDjRZL27Nmje++9V71799a4cePyb2ORrzw9PRUREeFwvDMyMrRy5UqH4/1HkZGRDv0lKS4uzt6/UqVKCgsLc+iTnJysTZs25bhOFA75MV6k/4WwgwcPasWKFSpZsmT+bAAslx9j5oknntDOnTvtP7Ps2LFDZcqU0dChQ/Xdd9/l38bgzyvo2UIAV2nfvr1p0KCB2bRpk1m3bp2pVq2aw3Tkv//+u6levbrZtGmTve3pp5825cuXN6tWrTI//vijiYyMNJGRkTm+xurVq5k1sYjIj/Gya9cuExwcbB5//HFz4sQJ+7+TJ09aum1wjXnz5hkvLy/z8ccfm71795oBAwaYwMBAk5CQYIwx5oknnjDDhg2z91+/fr0pVqyYefvtt82+ffvMyJEjs52+PjAw0HzxxRdm586d5sEHH2T6+iLC1eMlNTXVPPDAA6ZcuXJmx44dDp8pKSkpBbKNcK38+Iy5EbMm3toIYigyzpw5Y3r27Gn8/PyMv7+/6du3r7lw4YL9+cOHDxtJZvXq1fa2K1eumIEDB5o77rjD+Pj4mC5dupgTJ07k+BoEsaIjP8bLyJEjjaQs/ypUqGDhlsGVpk2bZsqXL288PT1N48aNzcaNG+3PRUVFmd69ezv0//zzz82dd95pPD09Te3atc3XX3/t8HxGRoZ59dVXTWhoqPHy8jJt2rQxBw4csGJTYAFXjpfMz6Ds/v3xcwmFm6s/Y25EELu12Yz5/ze9AAAAAAAswT1iAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAgCLDZrNpyZIlBV1Ggfv+++9ls9mUlJRU0KUAAHJAEAMAuJzNZsv136hRo3Jc9siRI7LZbNqxY8ctU9OtrFWrVnr++ecd2po1a6YTJ04oICCgYIoCANxUsYIuAABQ9Jw4ccL+//Pnz9eIESN04MABe5ufn98tXZMxRunp6SpWrHB+TXp6eiosLKygywAA5IIzYgAAlwsLC7P/CwgIkM1msz8OCQnRpEmTVK5cOXl5eal+/fpatmyZfdlKlSpJkho0aCCbzaZWrVpJkrZs2aK2bduqVKlSCggIUFRUlLZt2+aSmvbv368SJUro22+/VUREhLy8vLRu3TodOnRIDz74oEJDQ+Xn56e7775bK1ascFhvxYoV9frrr+vJJ59UiRIlVL58eb333nv251NTUzV48GCVLl1a3t7eqlChgsaPH29/ftKkSapbt658fX0VHh6ugQMH6uLFiw6vsX79erVq1Uo+Pj664447FBMTo3PnzqlPnz5as2aNpkyZYj+zd+TIkWwvTVy0aJFq164tLy8vVaxYURMnTnTpdgAAnEMQAwBYasqUKZo4caLefvtt7dy5UzExMXrggQd08OBBSdLmzZslSStWrNCJEye0ePFiSdKFCxfUu3dvrVu3Ths3blS1atXUoUMHXbhwwWW1DRs2TG+88Yb27dunevXq6eLFi+rQoYNWrlyp7du3q3379urUqZOOHj3qsNzEiRPVqFEjbd++XQMHDtQzzzxjP9s2depUffnll/r888914MABffbZZ6pYsaJ9WTc3N02dOlV79uzRJ598olWrVunvf/+7/fkdO3aoTZs2qlWrluLj47Vu3Tp16tRJ6enpmjJliiIjI9W/f3+dOHFCJ06cUHh4eJbt2rp1q7p3764ePXpo165dGjVqlF599VV9/PHHLtsOAICTDAAA+WjOnDkmICDA/rhMmTJm3LhxDn3uvvtuM3DgQGOMMYcPHzaSzPbt23Ndb3p6uilRooT56quv7G2SzH/+8x+na1q9erWRZJYsWXLTZWvXrm2mTZtmf1yhQgXz+OOP2x9nZGSYkJAQM2vWLGOMMc8++6xp3bq1ycjIuOm6jTFmwYIFpmTJkvbHPXv2NPfcc0+O/aOiosxzzz3n0Ja5PefOnTPGGPPoo4+atm3bOvQZOnSoqVWrVr5tBwAgd5wRAwBYJjk5WcePH9c999zj0H7PPfdo3759uS6bmJio/v37q1q1agoICJC/v78uXryY5ezUX9GoUSOHxxcvXtSLL76omjVrKjAwUH5+ftq3b1+W16xXr579/zMveTx58qQkqU+fPtqxY4eqV6+uIUOGaPny5Q7LrlixQm3atFHZsmVVokQJPfHEEzpz5owuX74s6X9nxP6Kffv2ZbvPDx48qPT0dJdsBwDAOQQxAECh0Lt3b+3YsUNTpkzRhg0btGPHDpUsWVKpqakuew1fX1+Hxy+++KL+85//6PXXX9fatWu1Y8cO1a1bN8trenh4ODy22WzKyMiQJDVs2FCHDx/W2LFjdeXKFXXv3l0PP/ywpOszRN5///2qV6+eFi1apK1bt2rGjBmSZH+N4sWLu2z7bubPbgcAwHkEMQCAZfz9/VWmTBmtX7/eoX39+vWqVauWpOsz/klyOFOT2WfIkCHq0KGDfdKJ06dP52u969evV58+fdSlSxfVrVtXYWFhOnLkiNPr8ff31yOPPKL3339f8+fP16JFi3T27Flt3bpVGRkZmjhxopo2bao777xTx48fd1i2Xr16WrlyZY7r9vT0zLKvblSzZs1s9/mdd94pd3f3v7wdAADnFc55eQEAhdbQoUM1cuRIValSRfXr19ecOXO0Y8cOffbZZ5KkkJAQFS9eXMuWLVO5cuXk7e2tgIAAVatWTf/85z/VqFEjJScna+jQofl+tqhatWpavHixOnXqJJvNpldffdV+hiivJk2apNKlS6tBgwZyc3PTggULFBYWpsDAQFWtWlVpaWmaNm2aOnXqpPXr12v27NkOyw8fPlx169bVwIED9fTTT8vT01OrV69Wt27dVKpUKVWsWFGbNm3SkSNH5Ofnp6CgoCw1vPDCC7r77rs1duxYPfLII4qPj9f06dM1c+ZMl2wHAMB5nBEDAFhqyJAhio2N1QsvvKC6detq2bJl+vLLL1WtWjVJUrFixTR16lS9++67KlOmjB588EFJ0ocffqhz586pYcOGeuKJJzRkyBCFhITka62TJk3SHXfcoWbNmqlTp06KiYlRw4YNnVpHiRIl9Oabb6pRo0a6++67deTIEX3zzTdyc3PTXXfdpUmTJmnChAmqU6eOPvvssyxTwt95551avny5fvrpJzVu3FiRkZH64osv7H/j7MUXX5S7u7tq1aql4ODgbO+Za9iwoT7//HPNmzdPderU0YgRIzRmzBj16dPHJdsBAHCezRhjCroIAAAAALid8GssAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIv9P7Oo+SBX2GpXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame containing the transaction data\n",
    "\n",
    "# Group data by date and calculate total transactions and success rate\n",
    "date_grouped = df.groupby('Date').agg({'Total Transactions': 'sum', 'Transaction Status': lambda x: (x == 'SUCCESS').mean()})\n",
    "\n",
    "# Filter data beyond 43000 transactions\n",
    "filtered_data = date_grouped[date_grouped['Total Transactions'] > 43000]\n",
    "\n",
    "# Plot the relationship between total transactions and success rate\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['Total Transactions'], filtered_data['Transaction Status'], color='blue')\n",
    "plt.xlabel('Total Transactions')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.title('Relationship between Total Transactions and Success Rate')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merchant-Bank Combination needing the most focus in terms of improving conversions:\n",
      "Merchant        Merchant 1\n",
      "Bank                Bank 1\n",
      "Success Rate      0.477273\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "success_rate_df = df.groupby(['Merchant', 'Bank'])['Transaction Status'] \\\n",
    "    .apply(lambda x: (x == 'SUCCESS').sum() / x.count()) \\\n",
    "    .reset_index(name='Success Rate')\n",
    "\n",
    "# Find the combination with the lowest success rate\n",
    "worst_combination = success_rate_df.loc[success_rate_df['Success Rate'].idxmin()]\n",
    "\n",
    "print(\"Merchant-Bank Combination needing the most focus in terms of improving conversions:\")\n",
    "print(worst_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator processing the maximum number of transactions for Bank 3: Agg4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the transaction data\n",
    "\n",
    "# Filter data for Bank 3 transactions\n",
    "bank3_data = df[df['Bank'] == 'Bank 3']\n",
    "\n",
    "# Group by Aggregator and calculate total transactions\n",
    "aggregator_transactions = bank3_data.groupby('Aggregator')['Total Transactions'].sum()\n",
    "\n",
    "# Find the aggregator with the maximum total transactions\n",
    "max_transactions_aggregator = aggregator_transactions.idxmax()\n",
    "\n",
    "print(\"Aggregator processing the maximum number of transactions for Bank 3:\", max_transactions_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of transactions without a transaction status: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Count the number of transactions without a transaction status\n",
    "transactions_without_status = df['Transaction Status'].isnull().sum()\n",
    "\n",
    "# Calculate the total number of transactions\n",
    "total_transactions = len(df)\n",
    "\n",
    "# Calculate the percentage of transactions without a transaction status\n",
    "percentage = (transactions_without_status / total_transactions) * 100\n",
    "\n",
    "print(\"Percentage of transactions without a transaction status:\", percentage, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst aggregator for Bank 2 and Merchant 1 (minimum 1000 transactions): Agg4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the transaction data\n",
    "\n",
    "# Filter data for Bank 2 and Merchant 1 transactions\n",
    "filtered_data = df[(df['Bank'] == 'Bank 2') & (df['Merchant'] == 'Merchant 1')]\n",
    "\n",
    "aggregator_transactions = filtered_data.groupby('Aggregator')['Total Transactions'].sum()\n",
    "\n",
    "aggregator_transactions = aggregator_transactions[aggregator_transactions >= 1000]\n",
    "if aggregator_transactions.empty:\n",
    "    print(\"No aggregator meets the minimum transaction threshold of 1000.\")\n",
    "else:\n",
    "    # Calculate success rate for each aggregator\n",
    "    success_rate = filtered_data[filtered_data['Transaction Status'] == 'SUCCESS'].groupby('Aggregator').size() / aggregator_transactions\n",
    "    \n",
    "    # Find the worst aggregator with the lowest success rate\n",
    "    worst_aggregator = success_rate.idxmin()\n",
    "    print(\"Worst aggregator for Bank 2 and Merchant 1 (minimum 1000 transactions):\", worst_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date with the maximum number of unique aggregators, merchants, and banks:\n",
      "Date          2016-04-20 00:00:00\n",
      "Aggregator                      5\n",
      "Merchant                        2\n",
      "Bank                            3\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df.groupby('Date').agg({\n",
    "    'Aggregator': 'nunique',\n",
    "    'Merchant': 'nunique',\n",
    "    'Bank': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Find the date with the maximum number of unique aggregators, merchants, and banks\n",
    "max_unique_date = unique_counts.loc[unique_counts[['Aggregator', 'Merchant', 'Bank']].sum(axis=1).idxmax()]\n",
    "\n",
    "print(\"Date with the maximum number of unique aggregators, merchants, and banks:\")\n",
    "print(max_unique_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date with the maximum number of sessions: 2016-04-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishn\\AppData\\Local\\Temp\\ipykernel_23268\\2020033119.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the transaction data\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group by date and sum the total transactions\n",
    "total_transactions_per_date = df.groupby('Date')['Total Transactions'].sum()\n",
    "\n",
    "# Find the date with the maximum number of sessions\n",
    "max_sessions_date = total_transactions_per_date.idxmax()\n",
    "\n",
    "print(\"Date with the maximum number of sessions:\", max_sessions_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date with the least success rate: 2016-04-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the transaction data\n",
    "\n",
    "# Calculate total transactions and successful transactions per date\n",
    "transactions_per_date = df.groupby('Date')['Total Transactions'].sum()\n",
    "successful_transactions_per_date = df[df['Transaction Status'] == 'SUCCESS'].groupby('Date')['Total Transactions'].sum()\n",
    "\n",
    "# Calculate success rate per date\n",
    "success_rate_per_date = successful_transactions_per_date / transactions_per_date\n",
    "\n",
    "# Find the date with the least success rate\n",
    "least_success_rate_date = success_rate_per_date.idxmin()\n",
    "\n",
    "print(\"Date with the least success rate:\", least_success_rate_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank with the best success rate: Bank 3\n",
      "Success rate: 0.8329276909790374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "successful_transactions = df[df['Transaction Status'] == 'SUCCESS']\n",
    "successful_transactions_per_bank = successful_transactions.groupby('Bank')['Total Transactions'].sum()\n",
    "\n",
    "total_transactions_per_bank = df.groupby('Bank')['Total Transactions'].sum()\n",
    "\n",
    "success_rate_per_bank = successful_transactions_per_bank / total_transactions_per_bank\n",
    "\n",
    "best_bank_success_rate = success_rate_per_bank.idxmax()\n",
    "best_bank_success_rate_value = success_rate_per_bank.max()\n",
    "\n",
    "print(\"Bank with the best success rate:\", best_bank_success_rate)\n",
    "print(\"Success rate:\", best_bank_success_rate_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best aggregator for Bank 1: Agg1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the transaction data\n",
    "\n",
    "# Filter data for Bank 1 transactions\n",
    "bank1_data = df[df['Bank'] == 'Bank 1']\n",
    "\n",
    "# Group by Aggregator and calculate total transactions and successful transactions\n",
    "aggregator_stats = bank1_data.groupby('Aggregator').agg(\n",
    "    total_transactions=('Total Transactions', 'sum'),\n",
    "    successful_transactions=('Transaction Status', lambda x: (x == 'SUCCESS').sum())\n",
    ")\n",
    "\n",
    "# Filter out aggregators with less than 500 transactions\n",
    "aggregator_stats = aggregator_stats[aggregator_stats['total_transactions'] >= 500]\n",
    "\n",
    "# Calculate success rate for each aggregator\n",
    "aggregator_stats['success_rate'] = aggregator_stats['successful_transactions'] / aggregator_stats['total_transactions']\n",
    "\n",
    "# Find the aggregator with the highest success rate\n",
    "best_aggregator = aggregator_stats['success_rate'].idxmax()\n",
    "\n",
    "print(\"Best aggregator for Bank 1:\", best_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Success Rate: 0.7866662103245645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the transaction data\n",
    "\n",
    "# Filter successful transactions\n",
    "successful_transactions = df[df['Transaction Status'] == 'SUCCESS']\n",
    "\n",
    "# Calculate the total number of successful transactions\n",
    "total_successful_transactions = successful_transactions['Total Transactions'].sum()\n",
    "\n",
    "# Calculate the total number of all transactions\n",
    "total_transactions = df['Total Transactions'].sum()\n",
    "\n",
    "# Calculate the overall success rate\n",
    "overall_success_rate = total_successful_transactions / total_transactions\n",
    "\n",
    "print(\"Overall Success Rate:\", overall_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m success_rates \u001b[38;5;241m=\u001b[39m selected_aggregators_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAggregator\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransaction Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUCCESS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Step 6: Identify the aggregator with the lowest success rate\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m worst_aggregator \u001b[38;5;241m=\u001b[39m \u001b[43msuccess_rates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Step 5: Calculate success rate for each aggregator\u001b[39;00m\n\u001b[0;32m     24\u001b[0m success_rates \u001b[38;5;241m=\u001b[39m filtered_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAggregator\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransaction Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUCCESS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:2557\u001b[0m, in \u001b[0;36mSeries.idxmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2552\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   2553\u001b[0m     \u001b[38;5;66;03m# TODO(3.0): this catching/filtering can be removed\u001b[39;00m\n\u001b[0;32m   2554\u001b[0m     \u001b[38;5;66;03m# ignore warning produced by argmin since we will issue a different\u001b[39;00m\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;66;03m#  warning for idxmin\u001b[39;00m\n\u001b[0;32m   2556\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2557\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;66;03m# GH#43587 give correct NA value for Index.\u001b[39;00m\n\u001b[0;32m   2561\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.idxmin with all-NA \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, or any-NA and skipna=False, is deprecated. In a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2566\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2567\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:785\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39margmin()\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 785\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanargmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    787\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    788\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.argmax/argmin \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    789\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith skipna=False and NAs, or with all-NAs is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    792\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    793\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1188\u001b[0m, in \u001b[0;36mnanargmin\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1186\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(values, \u001b[38;5;28;01mTrue\u001b[39;00m, fill_value_typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# error: Need type annotation for 'result'\u001b[39;00m\n\u001b[1;32m-> 1188\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_arg_null_out(result, axis, mask, skipna)\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Step 1: Filter data for Bank 2 and Merchant 1, and exclude null values in 'Aggregator' and 'Transaction Status' columns\n",
    "filtered_data = df[(df['Bank'] == 'Bank 2') & (df['Merchant'] == 'Merchant 1') & \n",
    "                   (~df['Aggregator'].isnull()) & (~df['Transaction Status'].isnull())]\n",
    "\n",
    "# Step 2: Group data by 'Aggregator' and count total transactions for each aggregator\n",
    "aggregator_volume = filtered_data['Aggregator'].value_counts()\n",
    "\n",
    "# Step 3: Exclude aggregators with transaction volume less than 1000\n",
    "aggregator_volume = aggregator_volume[aggregator_volume >= 1000]\n",
    "\n",
    "# Step 4: Filter original data to include only transactions for selected aggregators\n",
    "selected_aggregators_data = filtered_data[filtered_data['Aggregator'].isin(aggregator_volume.index)]\n",
    "\n",
    "# Step 5: Calculate success rate for each aggregator\n",
    "success_rates = selected_aggregators_data.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Step 6: Identify the aggregator with the lowest success rate\n",
    "worst_aggregator = success_rates.idxmin()\n",
    "# Step 5: Calculate success rate for each aggregator\n",
    "success_rates = filtered_data.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Step 6: Identify the aggregator with the lowest success rate\n",
    "worst_aggregator = success_rates[success_rates.index.isin(aggregator_volume.index)].idxmin()\n",
    "\n",
    "# Print the result\n",
    "print(\"Worst aggregator for Bank 2 and Merchant 1 with minimum volume of 1000 transactions:\", worst_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m success_rates \u001b[38;5;241m=\u001b[39m selected_aggregators_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAggregator\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransaction Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUCCESS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Step 6: Identify the aggregator with the lowest success rate\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m worst_aggregator \u001b[38;5;241m=\u001b[39m \u001b[43msuccess_rates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Print the result\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorst aggregator for Bank 2 and Merchant 1 with minimum volume of 1000 transactions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, worst_aggregator)\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:2557\u001b[0m, in \u001b[0;36mSeries.idxmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2552\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   2553\u001b[0m     \u001b[38;5;66;03m# TODO(3.0): this catching/filtering can be removed\u001b[39;00m\n\u001b[0;32m   2554\u001b[0m     \u001b[38;5;66;03m# ignore warning produced by argmin since we will issue a different\u001b[39;00m\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;66;03m#  warning for idxmin\u001b[39;00m\n\u001b[0;32m   2556\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2557\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;66;03m# GH#43587 give correct NA value for Index.\u001b[39;00m\n\u001b[0;32m   2561\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.idxmin with all-NA \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, or any-NA and skipna=False, is deprecated. In a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2566\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2567\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:785\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39margmin()\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 785\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanargmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    787\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    788\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.argmax/argmin \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    789\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith skipna=False and NAs, or with all-NAs is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    792\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    793\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1188\u001b[0m, in \u001b[0;36mnanargmin\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1186\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(values, \u001b[38;5;28;01mTrue\u001b[39;00m, fill_value_typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# error: Need type annotation for 'result'\u001b[39;00m\n\u001b[1;32m-> 1188\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_arg_null_out(result, axis, mask, skipna)\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Step 1: Filter data for Bank 2 and Merchant 1, and exclude null values in 'Aggregator' and 'Transaction Status' columns\n",
    "filtered_data = df[(df['Bank'] == 'Bank 2') & (df['Merchant'] == 'Merchant 1') & \n",
    "                   (~df['Aggregator'].isnull()) & (~df['Transaction Status'].isnull())]\n",
    "\n",
    "# Step 2: Group data by 'Aggregator' and count total transactions for each aggregator\n",
    "aggregator_volume = filtered_data['Aggregator'].value_counts()\n",
    "\n",
    "# Step 3: Exclude aggregators with transaction volume less than 1000\n",
    "aggregator_volume = aggregator_volume[aggregator_volume >= 1000]\n",
    "\n",
    "# Step 4: Filter original data to include only transactions for selected aggregators\n",
    "selected_aggregators_data = filtered_data[filtered_data['Aggregator'].isin(aggregator_volume.index)]\n",
    "\n",
    "# Step 5: Calculate success rate for each aggregator\n",
    "success_rates = selected_aggregators_data.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Step 6: Identify the aggregator with the lowest success rate\n",
    "worst_aggregator = success_rates.idxmin()\n",
    "\n",
    "# Print the result\n",
    "print(\"Worst aggregator for Bank 2 and Merchant 1 with minimum volume of 1000 transactions:\", worst_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date with maximum number of sessions: 2016-04-15 00:00:00\n",
      "Maximum number of sessions on that date: 45603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the sessions data\n",
    "\n",
    "# Group the data by 'Date' and sum the sessions for each date\n",
    "sessions_by_date = df.groupby('Date')['Total Transactions'].sum()\n",
    "\n",
    "# Find the date with the maximum number of sessions\n",
    "date_with_max_sessions = sessions_by_date.idxmax()\n",
    "max_sessions = sessions_by_date.max()\n",
    "\n",
    "print(\"Date with maximum number of sessions:\", date_with_max_sessions)\n",
    "print(\"Maximum number of sessions on that date:\", max_sessions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_transactions = df['Total Transactions'].sum()\n",
    "# # print(total_transactions)\n",
    "# # print(df['Total Transactions'].dtype)\n",
    "# average_transactions_per_day = df.groupby('Date')['Total Transactions'].mean()\n",
    "# # print(average_transactions_per_day)\n",
    "# failures_per_day = df[df['Transaction Status'] == 'FAILURE'].groupby('Date').size()\n",
    "# day_with_high_failures = failures_per_day.idxmax()\n",
    "# print(day_with_high_failures)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Success Rate: 0.5157068062827225\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Drop rows with null values in 'Aggregator' and 'Transaction Status' columns\n",
    "cleaned_df = df.dropna(subset=['Aggregator', 'Transaction Status'])\n",
    "\n",
    "# Count the total number of transactions after dropping null values\n",
    "total_transactions = len(cleaned_df)\n",
    "\n",
    "# Count the number of successful transactions\n",
    "successful_transactions = (cleaned_df['Transaction Status'] == 'SUCCESS').sum()\n",
    "\n",
    "# Calculate the overall success rate\n",
    "overall_success_rate = successful_transactions / total_transactions\n",
    "\n",
    "# Print the result\n",
    "print(\"Overall Success Rate:\", overall_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date with least success rate: 2016-04-28 00:00:00\n",
      "Least success rate on that date: 0.22727272727272727\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter out rows with successful transactions\n",
    "successful_transactions = df[df['Transaction Status'] == 'SUCCESS']\n",
    "\n",
    "# Group the data by 'Date' and count the total transactions for each date\n",
    "total_transactions_by_date = df.groupby('Date').size()\n",
    "\n",
    "# Group the successful transactions data by 'Date' and count the successful transactions for each date\n",
    "successful_transactions_by_date = successful_transactions.groupby('Date').size()\n",
    "\n",
    "# Calculate the success rate for each date\n",
    "success_rate_by_date = successful_transactions_by_date / total_transactions_by_date\n",
    "\n",
    "# Find the date with the least success rate\n",
    "date_with_least_success_rate = success_rate_by_date.idxmin()\n",
    "least_success_rate = success_rate_by_date.min()\n",
    "\n",
    "print(\"Date with least success rate:\", date_with_least_success_rate)\n",
    "print(\"Least success rate on that date:\", least_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merchant-Bank combination needing the most focus in terms of improving conversions:\n",
      "Merchant        Merchant 1\n",
      "Bank                Bank 1\n",
      "Success Rate      0.421053\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['Transaction Status'])\n",
    "\n",
    "# Calculating success rates for each merchant-bank combination\n",
    "success_rates = df.groupby(['Merchant', 'Bank'])['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean()).reset_index(name='Success Rate')\n",
    "\n",
    "# Identifying the merchant-bank combination with the lowest success rate\n",
    "lowest_success_rate_combination = success_rates.loc[success_rates['Success Rate'].idxmin()]\n",
    "\n",
    "print(\"Merchant-Bank combination needing the most focus in terms of improving conversions:\")\n",
    "print(lowest_success_rate_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Success Rate: 51.57%\n",
      "\n",
      "Success Rate by Aggregator:\n",
      "Aggregator\n",
      "Agg1    62.162162\n",
      "Agg2    50.581395\n",
      "Agg3    51.851852\n",
      "Agg4    50.000000\n",
      "Agg5    46.875000\n",
      "Name: Transaction Status, dtype: float64\n",
      "\n",
      "Success Rate by Bank:\n",
      "Bank\n",
      "Bank 1    49.137931\n",
      "Bank 2    51.428571\n",
      "Bank 3    53.968254\n",
      "Name: Transaction Status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Convert 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Drop rows with null values in 'Transaction Status' and 'Aggregator' columns\n",
    "df_cleaned = df.dropna(subset=['Transaction Status', 'Aggregator'])\n",
    "\n",
    "# Calculate success rate\n",
    "success_rate = (df_cleaned[df_cleaned['Transaction Status'] == 'SUCCESS'].shape[0] / df_cleaned.shape[0]) * 100\n",
    "print(\"Overall Success Rate: {:.2f}%\".format(success_rate))\n",
    "\n",
    "# Group by 'Aggregator' and calculate success rate for each aggregator\n",
    "aggregator_success_rate = df_cleaned.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean() * 100)\n",
    "print(\"\\nSuccess Rate by Aggregator:\")\n",
    "print(aggregator_success_rate)\n",
    "\n",
    "# Group by 'Bank' and calculate success rate for each bank\n",
    "bank_success_rate = df_cleaned.groupby('Bank')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean() * 100)\n",
    "print(\"\\nSuccess Rate by Bank:\")\n",
    "print(bank_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best day for Bank 1 through Aggregator 3 and for Merchant 2 (with a minimum of 500 transactions):\n",
      "Date            2016-04-14 00:00:00\n",
      "Success Rate                    0.5\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['Bank'] == 'Bank 1') & (df['Aggregator'] == 'Agg3') & (df['Merchant'] == 'Merchant 2')]\n",
    "\n",
    "# Group by Date and calculate success rate\n",
    "success_rates = filtered_df.groupby('Date')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean()).reset_index(name='Success Rate')\n",
    "\n",
    "# Select the day with the highest success rate\n",
    "best_day = success_rates.loc[success_rates['Success Rate'].idxmax()]\n",
    "\n",
    "print(\"Best day for Bank 1 through Aggregator 3 and for Merchant 2 (with a minimum of 500 transactions):\")\n",
    "print(best_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank with the best success rate: Bank 3\n",
      "Success rate of the best bank: 0.34274193548387094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter out rows with successful transactions\n",
    "successful_transactions = df[df['Transaction Status'] == 'SUCCESS']\n",
    "\n",
    "# Group the data by 'Bank' and count the total transactions for each bank\n",
    "total_transactions_by_bank = df.groupby('Bank').size()\n",
    "\n",
    "# Group the successful transactions data by 'Bank' and count the successful transactions for each bank\n",
    "successful_transactions_by_bank = successful_transactions.groupby('Bank').size()\n",
    "\n",
    "# Calculate the success rate for each bank\n",
    "success_rate_by_bank = successful_transactions_by_bank / total_transactions_by_bank\n",
    "\n",
    "# Find the bank with the best success rate\n",
    "best_bank_success_rate = success_rate_by_bank.idxmax()\n",
    "highest_success_rate = success_rate_by_bank.max()\n",
    "\n",
    "print(\"Bank with the best success rate:\", best_bank_success_rate)\n",
    "print(\"Success rate of the best bank:\", highest_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst aggregator for Bank 2 and Merchant 1 (with a minimum of 1000 transactions):\n",
      "Aggregator          Agg4\n",
      "Success Rate    0.482759\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['Bank'] == 'Bank 2') & (df['Merchant'] == 'Merchant 1')]\n",
    "agg_success_rates = filtered_df.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean()).reset_index(name='Success Rate')\n",
    "\n",
    "# Select the aggregator with the lowest success rate\n",
    "worst_aggregator = agg_success_rates.loc[agg_success_rates['Success Rate'].idxmin()]\n",
    "\n",
    "print(\"Worst aggregator for Bank 2 and Merchant 1 (with a minimum of 1000 transactions):\")\n",
    "print(worst_aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator\n",
      "Agg1    62.162162\n",
      "Agg2    50.581395\n",
      "Agg3    51.851852\n",
      "Agg4    50.000000\n",
      "Agg5    46.875000\n",
      "Name: Transaction Status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(aggregator_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2016-04-14    12\n",
      "2016-04-15    16\n",
      "2016-04-16    16\n",
      "2016-04-17    15\n",
      "2016-04-18    15\n",
      "2016-04-19    17\n",
      "2016-04-20    18\n",
      "2016-04-21    17\n",
      "2016-04-22    17\n",
      "2016-04-23    19\n",
      "2016-04-24    20\n",
      "2016-04-25    19\n",
      "2016-04-26    17\n",
      "2016-04-27    18\n",
      "2016-04-28    11\n",
      "dtype: int64\n",
      "The day with the highest number of failures was 2016-04-24 with 20 failures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishn\\AppData\\Local\\Temp\\ipykernel_23268\\1065073013.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to include only rows with non-null Transaction Status\n",
    "df_cleaned = df.dropna(subset=['Transaction Status'])\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n",
    "\n",
    "failures = df_cleaned[df_cleaned['Transaction Status'] == 'FAILURE']\n",
    "\n",
    "failures_by_date = failures.groupby('Date').size()\n",
    "print(failures_by_date)\n",
    "day_with_highest_failures = failures_by_date.idxmax()\n",
    "highest_failures_count = failures_by_date.max()\n",
    "\n",
    "print(\"The day with the highest number of failures was {} with {} failures.\".format(day_with_highest_failures.strftime('%Y-%m-%d'), highest_failures_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merchant with the highest success rate: Merchant 2\n",
      "Success rate: 0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "merchant_performance = df[df['Transaction Status'] == 'SUCCESS'].groupby('Merchant').size() / df.groupby('Merchant').size()\n",
    "\n",
    "merchant_performance_sorted = merchant_performance.sort_values(ascending=False)\n",
    "\n",
    "highest_success_rate_merchant = merchant_performance_sorted.index[0]\n",
    "\n",
    "success_rate = merchant_performance_sorted.iloc[0]\n",
    "\n",
    "print(\"Merchant with the highest success rate:\", highest_success_rate_merchant)\n",
    "print(\"Success rate:\", success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Total Transactions  Successful Transactions  Success Rate (%)\n",
      "Aggregator                                                               \n",
      "Agg1                        37                       23         62.162162\n",
      "Agg3                        81                       42         51.851852\n",
      "Agg2                       172                       87         50.581395\n",
      "Agg4                        60                       30         50.000000\n",
      "Agg5                        32                       15         46.875000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transaction data\n",
    "\n",
    "# Filter out rows with null values in 'Transaction Status' and 'Aggregator' columns\n",
    "df_filtered = df.dropna(subset=['Transaction Status', 'Aggregator'])\n",
    "\n",
    "# Group the data by 'Aggregator' and count the total transactions for each aggregator\n",
    "total_transactions = df_filtered.groupby('Aggregator').size()\n",
    "\n",
    "# Count the number of successful transactions for each aggregator\n",
    "successful_transactions = df_filtered[df_filtered['Transaction Status'] == 'SUCCESS'].groupby('Aggregator').size()\n",
    "\n",
    "# Calculate the success rate for each aggregator\n",
    "success_rate = (successful_transactions / total_transactions) * 100\n",
    "\n",
    "# Create a DataFrame to store the performance metrics\n",
    "aggregator_performance = pd.DataFrame({\n",
    "    'Total Transactions': total_transactions,\n",
    "    'Successful Transactions': successful_transactions,\n",
    "    'Success Rate (%)': success_rate\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by success rate in descending order\n",
    "aggregator_performance_sorted = aggregator_performance.sort_values(by='Success Rate (%)', ascending=False)\n",
    "\n",
    "print(aggregator_performance_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date with the highest number of failures: 2016-04-24 00:00:00\n",
      "Number of failures on that date: 20\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for rows where Transaction Status is not SUCCESS\n",
    "failures_df = df[df['Transaction Status'] == 'FAILURE']\n",
    "\n",
    "# Group by date and count the occurrences of failures for each date\n",
    "failures_by_date = failures_df.groupby('Date').size()\n",
    "\n",
    "# Find the date with the highest number of failures\n",
    "date_with_highest_failures = failures_by_date.idxmax()\n",
    "highest_failures_count = failures_by_date.max()\n",
    "\n",
    "print(\"Date with the highest number of failures:\", date_with_highest_failures)\n",
    "print(\"Number of failures on that date:\", highest_failures_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Total Transactions  Successful Transactions  Failed Transactions  \\\n",
      "Bank                                                                       \n",
      "Bank 3                 164                       85                   79   \n",
      "Bank 2                 172                       85                   87   \n",
      "Bank 1                 155                       74                   81   \n",
      "\n",
      "        Success Rate (%)  \n",
      "Bank                      \n",
      "Bank 3         51.829268  \n",
      "Bank 2         49.418605  \n",
      "Bank 1         47.741935  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transaction data\n",
    "\n",
    "# Filter out rows with null values in 'Transaction Status' and 'Bank' columns\n",
    "df_filtered = df.dropna(subset=['Transaction Status', 'Bank'])\n",
    "\n",
    "# Group the data by 'Bank' and count the total transactions for each bank\n",
    "total_transactions = df_filtered.groupby('Bank').size()\n",
    "\n",
    "# Count the number of successful transactions for each bank\n",
    "successful_transactions = df_filtered[df_filtered['Transaction Status'] == 'SUCCESS'].groupby('Bank').size()\n",
    "\n",
    "# Count the number of failed transactions for each bank\n",
    "failed_transactions = df_filtered[df_filtered['Transaction Status'] != 'SUCCESS'].groupby('Bank').size()\n",
    "\n",
    "# Calculate the success rate for each bank\n",
    "success_rate = (successful_transactions / total_transactions) * 100\n",
    "\n",
    "# Create a DataFrame to store the performance metrics\n",
    "bank_performance = pd.DataFrame({\n",
    "    'Total Transactions': total_transactions,\n",
    "    'Successful Transactions': successful_transactions,\n",
    "    'Failed Transactions': failed_transactions,\n",
    "    'Success Rate (%)': success_rate\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by success rate in descending order\n",
    "bank_performance_sorted = bank_performance.sort_values(by='Success Rate (%)', ascending=False)\n",
    "\n",
    "print(bank_performance_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall success rate for two weeks: 0.3249001331557923\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter the data for two weeks\n",
    "start_date = pd.to_datetime('2016-04-14')\n",
    "end_date = pd.to_datetime('2016-04-28')\n",
    "two_weeks_data = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "\n",
    "# Count total transactions\n",
    "total_transactions = len(two_weeks_data)\n",
    "\n",
    "# Count successful transactions\n",
    "successful_transactions = len(two_weeks_data[two_weeks_data['Transaction Status'] == 'SUCCESS'])\n",
    "\n",
    "# Calculate overall success rate\n",
    "overall_success_rate = successful_transactions / total_transactions\n",
    "\n",
    "print(\"Overall success rate for two weeks:\", overall_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m aggregator_stats \u001b[38;5;241m=\u001b[39m aggregator_stats[aggregator_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_transactions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Find the aggregator offering the highest success rate for Bank 1\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m best_aggregator \u001b[38;5;241m=\u001b[39m \u001b[43maggregator_stats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuccess_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Print the result\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest aggregator for Bank 1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_aggregator)\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:2641\u001b[0m, in \u001b[0;36mSeries.idxmax\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2636\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   2637\u001b[0m     \u001b[38;5;66;03m# TODO(3.0): this catching/filtering can be removed\u001b[39;00m\n\u001b[0;32m   2638\u001b[0m     \u001b[38;5;66;03m# ignore warning produced by argmax since we will issue a different\u001b[39;00m\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m#  warning for argmax\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2641\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2644\u001b[0m     \u001b[38;5;66;03m# GH#43587 give correct NA value for Index.\u001b[39;00m\n\u001b[0;32m   2645\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2646\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.idxmax with all-NA \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2647\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, or any-NA and skipna=False, is deprecated. In a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2650\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2651\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:751\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmax\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39margmax()\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanargmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    753\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    754\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.argmax/argmin \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    755\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith skipna=False and NAs, or with all-NAs is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    758\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    759\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1143\u001b[0m, in \u001b[0;36mnanargmax\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1141\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(values, \u001b[38;5;28;01mTrue\u001b[39;00m, fill_value_typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m# error: Need type annotation for 'result'\u001b[39;00m\n\u001b[1;32m-> 1143\u001b[0m result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39margmax(axis)  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_arg_null_out(result, axis, mask, skipna)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter data to exclude null values in 'Aggregator' column and only include transactions for Bank 1\n",
    "filtered_data = df[(~df['Aggregator'].isnull()) & (df['Bank'] == 'Bank 1')]\n",
    "\n",
    "# Group data by 'Aggregator'\n",
    "grouped_data = filtered_data.groupby('Aggregator')\n",
    "\n",
    "# Calculate total transactions and success rate for each aggregator\n",
    "aggregator_stats = grouped_data.agg(\n",
    "    total_transactions=('Transaction Status', 'count'),\n",
    "    successful_transactions=('Transaction Status', lambda x: (x == 'SUCCESS').sum())\n",
    ")\n",
    "\n",
    "# Calculate success rate\n",
    "aggregator_stats['success_rate'] = aggregator_stats['successful_transactions'] / aggregator_stats['total_transactions']\n",
    "\n",
    "# Filter aggregators with minimum 500 transactions\n",
    "aggregator_stats = aggregator_stats[aggregator_stats['total_transactions'] >= 500]\n",
    "\n",
    "# Find the aggregator offering the highest success rate for Bank 1\n",
    "best_aggregator = aggregator_stats['success_rate'].idxmax()\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Step 1: Filter data for Bank 2 and Merchant 1, and exclude null values in 'Aggregator' column\n",
    "filtered_data = df[(df['Bank'] == 'Bank 2') & (df['Merchant'] == 'Merchant 1') & (~df['Aggregator'].isnull())]\n",
    "\n",
    "# Step 2: Group data by 'Aggregator' and count total transactions for each aggregator\n",
    "aggregator_volume = filtered_data['Aggregator'].value_counts()\n",
    "\n",
    "# Step 3: Exclude aggregators with transaction volume less than 1000\n",
    "aggregator_volume = aggregator_volume[aggregator_volume >= 1000]\n",
    "\n",
    "# Step 4: Filter original data to include only transactions for selected aggregators\n",
    "selected_aggregators_data = filtered_data[filtered_data['Aggregator'].isin(aggregator_volume.index)]\n",
    "\n",
    "# Step 5: Calculate success rate for each aggregatorimport pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Step 1: Filter data for Bank 2 and Merchant 1, and exclude null values in 'Aggregator' column\n",
    "filtered_data = df[(df['Bank'] == 'Bank 2') & (df['Merchant'] == 'Merchant 1') & (~df['Aggregator'].isnull())]\n",
    "\n",
    "# Step 2: Group data by 'Aggregator' and count total transactions for each aggregator\n",
    "aggregator_volume = filtered_data['Aggregator'].value_counts()\n",
    "\n",
    "# Step 3: Exclude aggregators with transaction volume less than 1000\n",
    "aggregator_volume = aggregator_volume[aggregator_volume >= 1000]\n",
    "\n",
    "# Step 4: Filter original data to include only transactions for selected aggregators\n",
    "selected_aggregators_data = filtered_data[filtered_data['Aggregator'].isin(aggregator_volume.index)]\n",
    "\n",
    "# Step 5: Calculate success rate for each aggregator\n",
    "success_rates = selected_aggregators_data.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Step 6: Identify the aggregator with the lowest success rate\n",
    "worst_aggregator = success_rates.idxmin()\n",
    "\n",
    "# Print the result\n",
    "print(\"Worst aggregator for Bank 2 and Merchant 1 with minimum volume of 1000 transactions:\", worst_aggregator)\n",
    "\n",
    "success_rates = selected_aggregators_data.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Step 6: Identify the aggregator with the lowest success rate\n",
    "worst_aggregator = success_rates.idxmin()\n",
    "\n",
    "# Print the result\n",
    "print(\"Worst aggregator for Bank 2 and Merchant 1 with minimum volume of 1000 transactions:\", worst_aggregator)\n",
    "\n",
    "# Print the result\n",
    "print(\"Best aggregator for Bank 1:\", best_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator with maximum volume for Bank 3: Agg2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter data to exclude null values in 'Aggregator' column and only include transactions for Bank 3\n",
    "filtered_data = df[(~df['Aggregator'].isnull()) & (df['Bank'] == 'Bank 3')]\n",
    "\n",
    "# Group data by 'Aggregator' and calculate total transactions for each aggregator\n",
    "aggregator_volume = filtered_data.groupby('Aggregator')['Transaction Status'].count()\n",
    "\n",
    "# Find the aggregator with maximum volume for Bank 3\n",
    "max_volume_aggregator = aggregator_volume.idxmax()\n",
    "\n",
    "# Print the result\n",
    "print(\"Aggregator with maximum volume for Bank 3:\", max_volume_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m success_rates \u001b[38;5;241m=\u001b[39m selected_aggregators_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAggregator\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransaction Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUCCESS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Identify the aggregator with the lowest success rate\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m worst_aggregator \u001b[38;5;241m=\u001b[39m \u001b[43msuccess_rates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Print the result\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorst aggregator for Bank 2 and Merchant 1 with minimum volume of 1000 transactions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, worst_aggregator)\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:2557\u001b[0m, in \u001b[0;36mSeries.idxmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2552\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   2553\u001b[0m     \u001b[38;5;66;03m# TODO(3.0): this catching/filtering can be removed\u001b[39;00m\n\u001b[0;32m   2554\u001b[0m     \u001b[38;5;66;03m# ignore warning produced by argmin since we will issue a different\u001b[39;00m\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;66;03m#  warning for idxmin\u001b[39;00m\n\u001b[0;32m   2556\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2557\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;66;03m# GH#43587 give correct NA value for Index.\u001b[39;00m\n\u001b[0;32m   2561\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.idxmin with all-NA \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, or any-NA and skipna=False, is deprecated. In a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2566\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2567\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:785\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39margmin()\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 785\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanargmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    787\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    788\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.argmax/argmin \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    789\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith skipna=False and NAs, or with all-NAs is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    792\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    793\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1188\u001b[0m, in \u001b[0;36mnanargmin\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1186\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(values, \u001b[38;5;28;01mTrue\u001b[39;00m, fill_value_typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# error: Need type annotation for 'result'\u001b[39;00m\n\u001b[1;32m-> 1188\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_arg_null_out(result, axis, mask, skipna)\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter data for Bank 2 and Merchant 1, and exclude null values in 'Aggregator' column\n",
    "filtered_data = df[(df['Bank'] == 'Bank 2') & (df['Merchant'] == 'Merchant 1') & (~df['Aggregator'].isnull())]\n",
    "\n",
    "# Group data by 'Aggregator' and count total transactions for each aggregator\n",
    "aggregator_volume = filtered_data.groupby('Aggregator').size()\n",
    "\n",
    "# Exclude aggregators with transaction volume less than 1000\n",
    "aggregator_volume = aggregator_volume[aggregator_volume >= 1000]\n",
    "\n",
    "# Filter original data to include only transactions for selected aggregators\n",
    "selected_aggregators_data = filtered_data[filtered_data['Aggregator'].isin(aggregator_volume.index)]\n",
    "\n",
    "# Calculate success rate for each aggregator\n",
    "success_rates = selected_aggregators_data.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Identify the aggregator with the lowest success rate\n",
    "worst_aggregator = success_rates.idxmin()\n",
    "\n",
    "# Print the result\n",
    "print(\"Worst aggregator for Bank 2 and Merchant 1 with minimum volume of 1000 transactions:\", worst_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date with maximum number of sessions is: Total Transactions   2016-04-25\n",
      "Merchant             2016-04-25\n",
      "Aggregator           2016-04-25\n",
      "Bank                 2016-04-25\n",
      "Transaction Status   2016-04-25\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "max_sessions_date = df.groupby('Date').count().idxmax()\n",
    "print(f\"The date with maximum number of sessions is: {max_sessions_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Bank  total_transactions  successful_transactions  success_rate\n",
      "2  Bank 3               37834                       68      0.539683\n",
      "1  Bank 2              132451                       72      0.514286\n",
      "0  Bank 1              205837                       57      0.491379\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.dropna(subset=['Aggregator', 'Transaction Status'])\n",
    "\n",
    "# Grouping data by 'Bank'\n",
    "grouped = df_filtered.groupby('Bank')\n",
    "\n",
    "# Calculating metrics\n",
    "bank_performance = grouped.agg(\n",
    "    total_transactions=('Total Transactions', 'sum'),\n",
    "    successful_transactions=('Transaction Status', lambda x: x.eq('SUCCESS').sum()),\n",
    "    success_rate=('Transaction Status', lambda x: x.eq('SUCCESS').mean())\n",
    ").reset_index()\n",
    "\n",
    "# Sorting banks based on success rate\n",
    "bank_performance_sorted = bank_performance.sort_values(by='success_rate', ascending=False)\n",
    "\n",
    "print(bank_performance_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merchant with the best success rate is Merchant 2 with a success rate of 35.71%\n"
     ]
    }
   ],
   "source": [
    "# df['Transaction Status'] = df['Transaction Status'].apply(lambda x: True if x == 'SUCCESS' else False)\n",
    "\n",
    "# # Group by 'Merchant' and calculate success rate\n",
    "# success_rates = df.groupby('Merchant')['Transaction Status'].mean()\n",
    "\n",
    "# # Find the merchant with the highest success rate\n",
    "# best_merchant = success_rates.idxmax()\n",
    "# best_success_rate = success_rates.max()\n",
    "\n",
    "# print(f\"The merchant with the best success rate is {best_merchant} with a success rate of {best_success_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Total Transactions</th>\n",
       "      <th>Merchant</th>\n",
       "      <th>Aggregator</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Transaction Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>21</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>9</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>3</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>7</td>\n",
       "      <td>Merchant 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>680</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>1912</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg4</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2343</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>85</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>481</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg4</td>\n",
       "      <td>Bank 3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>22</td>\n",
       "      <td>Merchant 1</td>\n",
       "      <td>Agg2</td>\n",
       "      <td>Bank 3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Total Transactions    Merchant Aggregator    Bank  \\\n",
       "0   2016-04-14                  21  Merchant 1       Agg2  Bank 2   \n",
       "1   2016-04-14                   9  Merchant 2       Agg2  Bank 2   \n",
       "2   2016-04-14                   3  Merchant 2       Agg2  Bank 1   \n",
       "3   2016-04-14                   7  Merchant 2        NaN  Bank 1   \n",
       "4   2016-04-14                 680  Merchant 1       Agg2  Bank 1   \n",
       "..         ...                 ...         ...        ...     ...   \n",
       "746 2016-04-28                1912  Merchant 1       Agg4  Bank 2   \n",
       "747 2016-04-28                2343  Merchant 1       Agg2  Bank 1   \n",
       "748 2016-04-28                  85  Merchant 1       Agg2  Bank 2   \n",
       "749 2016-04-28                 481  Merchant 1       Agg4  Bank 3   \n",
       "750 2016-04-28                  22  Merchant 1       Agg2  Bank 3   \n",
       "\n",
       "     Transaction Status  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                  True  \n",
       "3                  True  \n",
       "4                 False  \n",
       "..                  ...  \n",
       "746                True  \n",
       "747                True  \n",
       "748                True  \n",
       "749                True  \n",
       "750                True  \n",
       "\n",
       "[751 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator with the highest success rate: Agg1\n",
      "Success rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "# aggregator_group = df.groupby('Aggregator')\n",
    "\n",
    "# # Step 2: Calculate success rate for each aggregator\n",
    "# success_rate = aggregator_group['Transaction Status'].apply(lambda x: (x == 'SUCCESS').sum() / len(x))\n",
    "\n",
    "# # Step 3: Find the aggregator with the highest success rate\n",
    "# best_aggregator = success_rate.idxmax()\n",
    "# highest_success_rate = success_rate.max()\n",
    "\n",
    "# print(\"Aggregator with the highest success rate:\", best_aggregator)\n",
    "# print(\"Success rate:\", highest_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Failure Count\n",
      "9   4/23/2016             39\n",
      "10  4/24/2016             39\n",
      "11  4/25/2016             39\n",
      "13  4/27/2016             37\n",
      "7   4/21/2016             36\n",
      "12  4/26/2016             36\n",
      "6   4/20/2016             35\n",
      "8   4/22/2016             35\n",
      "5   4/19/2016             34\n",
      "1   4/15/2016             33\n",
      "2   4/16/2016             33\n",
      "4   4/18/2016             33\n",
      "3   4/17/2016             32\n",
      "0   4/14/2016             29\n",
      "14  4/28/2016             17\n"
     ]
    }
   ],
   "source": [
    "# # Filter out rows with non-successful transactions\n",
    "# failure_transactions = df[df['Transaction Status'] != 'SUCCESS']\n",
    "\n",
    "# # Group the filtered data by the 'Date' column and count failures\n",
    "# failure_counts_by_date = failure_transactions.groupby('Date').size().reset_index(name='Failure Count')\n",
    "\n",
    "# # Sort dates based on the number of failures\n",
    "# sorted_dates_by_failure = failure_counts_by_date.sort_values(by='Failure Count', ascending=False)\n",
    "\n",
    "# print(sorted_dates_by_failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No aggregators meet the minimum volume threshold for Bank 2 and Merchant 1.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter transactions involving bank 2 and merchant 1\n",
    "filtered_df = df[(df['Bank'] == 'Bank 2') & (df['Merchant'] == 'Merchant 1')]\n",
    "\n",
    "# Calculate transaction volume for each aggregator\n",
    "aggregator_volume = filtered_df['Aggregator'].value_counts()\n",
    "\n",
    "# Filter aggregators with volume >= 1000\n",
    "aggregators_above_min_volume = aggregator_volume[aggregator_volume >= 1000].index.tolist()\n",
    "\n",
    "if len(aggregators_above_min_volume) == 0:\n",
    "    print(\"No aggregators meet the minimum volume threshold for Bank 2 and Merchant 1.\")\n",
    "else:\n",
    "    # Filter transactions involving aggregators above minimum volume\n",
    "    filtered_df = filtered_df[filtered_df['Aggregator'].isin(aggregators_above_min_volume)]\n",
    "\n",
    "    # Calculate success rate for each aggregator\n",
    "    success_rates = filtered_df.groupby('Aggregator')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "    # Check if there are any success rates\n",
    "    if len(success_rates) == 0:\n",
    "        print(\"No successful transactions found for Bank 2 and Merchant 1.\")\n",
    "    else:\n",
    "        # Identify the worst aggregator with the lowest success rate\n",
    "        worst_aggregator = success_rates.idxmin()\n",
    "        print(\"Worst Aggregator for Bank 2 and Merchant 1 with minimum volume of 1000 transactions:\", worst_aggregator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter transactions beyond 43000 transactions\n",
    "filtered_df = df[df['Total Transactions'] > 43000]\n",
    "\n",
    "# Calculate success rate for each volume level\n",
    "success_rate_by_volume = filtered_df.groupby('Total Transactions')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Check if success rate consistently decreases with an increase in volume\n",
    "success_rate_decreasing = all(success_rate_by_volume.diff().dropna() <= 0)\n",
    "\n",
    "print(\"True\" if success_rate_decreasing else \"False\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m success_rate_by_date \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransaction Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUCCESS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Filter out dates with fewer than 500 transactions\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m success_rate_by_date \u001b[38;5;241m=\u001b[39m \u001b[43msuccess_rate_by_date\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Transactions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Find the date with the highest success rate\u001b[39;00m\n\u001b[0;32m     15\u001b[0m best_date \u001b[38;5;241m=\u001b[39m success_rate_by_date\u001b[38;5;241m.\u001b[39midxmax()\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1068\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_slice(key)\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1068\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:2575\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2573\u001b[0m indexer \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_indexer_for(index)\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[1;32m-> 2575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[0;32m   2576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2579\u001b[0m     )\n\u001b[0;32m   2581\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter data for Bank 1, Aggregator 3, and Merchant 2\n",
    "filtered_df = df[(df['Bank'] == 'Bank 1') & (df['Aggregator'] == 'Agg3') & (df['Merchant'] == 'Merchant 2')]\n",
    "\n",
    "# Group data by date and calculate success rate\n",
    "success_rate_by_date = filtered_df.groupby('Date')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Filter out dates with fewer than 500 transactions\n",
    "success_rate_by_date = success_rate_by_date[filtered_df.groupby('Date')['Total Transactions'].transform('sum') >= 500]\n",
    "\n",
    "# Find the date with the highest success rate\n",
    "best_date = success_rate_by_date.idxmax()\n",
    "best_success_rate = success_rate_by_date.max()\n",
    "\n",
    "print(\"Best date with highest success rate for Bank 1 through Aggregator 3 for Merchant 2 (minimum 500 transactions):\")\n",
    "print(\"Date:\", best_date)\n",
    "print(\"Success Rate:\", best_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m success_rate_by_date \u001b[38;5;241m=\u001b[39m success_rate_by_date\u001b[38;5;241m.\u001b[39mloc[valid_dates]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Find the date with the highest success rate\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m best_date \u001b[38;5;241m=\u001b[39m \u001b[43msuccess_rate_by_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m best_success_rate \u001b[38;5;241m=\u001b[39m success_rate_by_date\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest date with highest success rate for Bank 1 through Aggregator 3 for Merchant 2 (minimum 500 transactions):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:2641\u001b[0m, in \u001b[0;36mSeries.idxmax\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2636\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   2637\u001b[0m     \u001b[38;5;66;03m# TODO(3.0): this catching/filtering can be removed\u001b[39;00m\n\u001b[0;32m   2638\u001b[0m     \u001b[38;5;66;03m# ignore warning produced by argmax since we will issue a different\u001b[39;00m\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m#  warning for argmax\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2641\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2644\u001b[0m     \u001b[38;5;66;03m# GH#43587 give correct NA value for Index.\u001b[39;00m\n\u001b[0;32m   2645\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2646\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.idxmax with all-NA \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2647\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, or any-NA and skipna=False, is deprecated. In a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2650\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2651\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:751\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmax\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39margmax()\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanargmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    753\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    754\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.argmax/argmin \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    755\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith skipna=False and NAs, or with all-NAs is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    758\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    759\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1143\u001b[0m, in \u001b[0;36mnanargmax\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1141\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(values, \u001b[38;5;28;01mTrue\u001b[39;00m, fill_value_typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m# error: Need type annotation for 'result'\u001b[39;00m\n\u001b[1;32m-> 1143\u001b[0m result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39margmax(axis)  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_arg_null_out(result, axis, mask, skipna)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the transactions data\n",
    "\n",
    "# Filter data for Bank 1, Aggregator 3, and Merchant 2\n",
    "filtered_df = df[(df['Bank'] == 'Bank 1') & (df['Aggregator'] == 'Agg3') & (df['Merchant'] == 'Merchant 2')]\n",
    "\n",
    "# Group data by date and calculate success rate\n",
    "success_rate_by_date = filtered_df.groupby('Date')['Transaction Status'].apply(lambda x: (x == 'SUCCESS').mean())\n",
    "\n",
    "# Filter out dates with fewer than 500 transactions\n",
    "valid_dates = filtered_df['Date'].value_counts()[filtered_df['Date'].value_counts() >= 500].index\n",
    "success_rate_by_date = success_rate_by_date.loc[valid_dates]\n",
    "\n",
    "# Find the date with the highest success rate\n",
    "best_date = success_rate_by_date.idxmax()\n",
    "best_success_rate = success_rate_by_date.max()\n",
    "\n",
    "print(\"Best date with highest success rate for Bank 1 through Aggregator 3 for Merchant 2 (minimum 500 transactions):\")\n",
    "print(\"Date:\", best_date)\n",
    "print(\"Success Rate:\", best_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (463370588.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[69], line 20\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Overall Success Rate:\", overall_success_rate\u001b[0m\n\u001b[1;37m                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the transaction data\n",
    "\n",
    "# Drop rows with null values in Transaction Status and Aggregator columns\n",
    "df_cleaned = df.dropna(subset=['Transaction Status', 'Aggregator'])\n",
    "\n",
    "# Filter successful transactions\n",
    "successful_transactions = df_cleaned[df_cleaned['Transaction Status'] == 'SUCCESS']\n",
    "\n",
    "# Calculate the total number of successful transactions\n",
    "total_successful_transactions = successful_transactions['Total Transactions'].sum()\n",
    "\n",
    "# Calculate the total number of all transactions\n",
    "total_transactions = df_cleaned['Total Transactions'].sum()\n",
    "\n",
    "# Calculate the overall success rate\n",
    "overall_success_rate = total_successful_transactions / total_transactions\n",
    "\n",
    "print(\"Overall Success Rate:\", overall_success_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Success Rate: 0.7862555234737665\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df.dropna(subset=['Transaction Status', 'Aggregator'])\n",
    "\n",
    "# Filter successful transactions\n",
    "successful_transactions = df_cleaned[df_cleaned['Transaction Status'] == 'SUCCESS']\n",
    "\n",
    "# Calculate the total number of successful transactions\n",
    "total_successful_transactions = successful_transactions['Total Transactions'].sum()\n",
    "\n",
    "# Calculate the total number of all transactions\n",
    "total_transactions = df_cleaned['Total Transactions'].sum()\n",
    "\n",
    "# Calculate the overall success rate\n",
    "overall_success_rate = total_successful_transactions / total_transactions\n",
    "\n",
    "print(\"Overall Success Rate:\", overall_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
